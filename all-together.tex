\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{all-together}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    Initialization. As I use functions from the tranX model to compute bleu,
it is necessary to add path to the folder to the system path (maybe
better just add them here?)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{196}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{json}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{from} \PY{n+nn}{mpl\PYZus{}toolkits}\PY{n+nn}{.}\PY{n+nn}{mplot3d} \PY{k}{import} \PY{n}{Axes3D}
\PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{cm}
\PY{k+kn}{import} \PY{n+nn}{random}
\PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
\PY{k+kn}{from} \PY{n+nn}{operator} \PY{k}{import} \PY{n}{itemgetter}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{pearsonr} \PY{k}{as} \PY{n}{pear}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{spearmanr} \PY{k}{as} \PY{n}{spear}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{kendalltau} \PY{k}{as} \PY{n}{kend}
\PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{stats}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{sys}
\PY{n}{sys}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{getcwd}\PY{p}{(}\PY{p}{)}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/../datasets/tranX/datasets/conala/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{197}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{myround}\PY{p}{(}\PY{n}{a}\PY{p}{,} \PY{n}{b}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{}for averaging Misha and Egor grades}
    \PY{k}{if} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
        \PY{k}{return} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{p}{(}\PY{n}{a}\PY{o}{+}\PY{n}{b}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{return} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{p}{(}\PY{n}{a}\PY{o}{+}\PY{n}{b}\PY{o}{+}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
\PY{k}{def} \PY{n+nf}{myroundlist}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{}for averaging multiple grades for same snippet}
    \PY{k}{if} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
        \PY{k}{return} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{o}{/}\PY{n+nb}{len}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{k}{return} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{o}{+}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{o}{/}\PY{n+nb}{len}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{data-preprocessing}{%
\section{Data preprocessing}\label{data-preprocessing}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{198}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{translate}\PY{n+nn}{.}\PY{n+nn}{bleu\PYZus{}score} \PY{k}{import} \PY{n}{sentence\PYZus{}bleu}\PY{p}{,} \PY{n}{SmoothingFunction}\PY{p}{,} \PY{n}{corpus\PYZus{}bleu}
\PY{k+kn}{from} \PY{n+nn}{conala\PYZus{}eval} \PY{k}{import} \PY{n}{tokenize\PYZus{}for\PYZus{}bleu\PYZus{}eval} \PY{k}{as} \PY{n}{tknz}
\PY{k+kn}{from} \PY{n+nn}{bleu\PYZus{}score} \PY{k}{import} \PY{n}{compute\PYZus{}bleu}
\PY{k+kn}{import} \PY{n+nn}{myrouge} \PY{k}{as} \PY{n+nn}{rouge}
\PY{k+kn}{import} \PY{n+nn}{mymeteor} \PY{k}{as} \PY{n+nn}{mym}
\PY{n}{fields} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{all\PYZus{}fields} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{all\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{metrics} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    The original dataset is dirty: there are questions with literally same
intent (and same question\_id) that appear several times in the
conala-test with different reference snippets. This corresponds to the
multiple reference solutions that should be considered for the metrics
computation. Beforehand we didn't pay attention, which lead to the wrong
results for the metrics accuracy (the results were artificially lowered,
as the model could only guess one possible form of snippet from one
intent, see clean\_dataset{[}5{]} for an example). Therefore, we need to
glue together cases with the same snippets; the original dataset is
called `dirty\_dataset' and the one with pruned examples is called
`clean\_dataset'.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{199}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}dirty\PYZus{}dataset = json.load(open(\PYZsq{}./metrics\PYZhy{}evaluation/to\PYZhy{}grade/all\PYZhy{}singles.json\PYZsq{}))}
\PY{n}{dirty\PYZus{}dataset} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./to\PYZhy{}grade/all\PYZhy{}singles.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{dirty\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{v} \PY{o+ow}{in} \PY{n}{d}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{d}\PY{p}{[}\PY{n}{k}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{v}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{200}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{all\PYZus{}names}\PY{p}{:}
                \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}dataset} \PY{o}{=} \PY{p}{[}\PY{n}{dirty\PYZus{}dataset}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{bleu}{%
\subsection{BLEU}\label{bleu}}

    This (and the next following sections) correspond to the metric
computation. The only thing to notice is that BLEU results depend on the
smoothing function (smooth = SmoothingFunction().method\#; \# is the
number from 1 to 5). In the end we get updated clean\_dataset with all
grades for all metrics

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{201}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{hyp} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{hp}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{hp} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}
        \PY{n}{snp} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{sn}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{sn} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
        \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}bleu\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{n}{snp}\PY{p}{]}\PY{p}{,} \PY{n}{hyp}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{rouge-l}{%
\subsection{ROUGE-L}\label{rouge-l}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{202}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{evaluator} \PY{o}{=} \PY{n}{rouge}\PY{o}{.}\PY{n}{Rouge}\PY{p}{(}\PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}l}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                           \PY{n}{max\PYZus{}n}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}
                           \PY{n}{limit\PYZus{}length}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
                           \PY{n}{length\PYZus{}limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}
                           \PY{n}{length\PYZus{}limit\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{words}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{c+c1}{\PYZsh{} Default F1\PYZus{}score}
                           \PY{n}{weight\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{1.2}\PY{p}{)}
\PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{keyn} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}rougel\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{nam}
    \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
        \PY{n}{hypt} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{n}{nam}\PY{p}{]}
        \PY{n}{refr} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{k}{if} \PY{n}{hypt}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o+ow}{is} \PY{o+ow}{not} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
            \PY{n}{scores} \PY{o}{=} \PY{n}{evaluator}\PY{o}{.}\PY{n}{get\PYZus{}scores}\PY{p}{(}\PY{n}{hypt}\PY{p}{,} \PY{n}{refr}\PY{p}{)}
            \PY{n}{d}\PY{p}{[}\PY{n}{keyn}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}l}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keyn}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{meteor}{%
\subsection{METEOR}\label{meteor}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{203}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{keyn} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}meteor\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{nam}
    \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
        \PY{n}{hypt} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{refr} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{k}{if} \PY{n}{hypt} \PY{o+ow}{is} \PY{o+ow}{not} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keyn}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{mym}\PY{o}{.}\PY{n}{meteor\PYZus{}score}\PY{p}{(}\PY{n}{refr}\PY{p}{,} \PY{n}{hypt}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keyn}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{ruby}{%
\subsection{RUBY}\label{ruby}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{204}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{ruby}\PY{n+nn}{.}\PY{n+nn}{similarity} \PY{k}{import} \PY{n}{ruby} \PY{k}{as} \PY{n}{ruby}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{205}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{ruby\PYZus{}grade} \PY{o}{=} \PY{l+m+mf}{0.0}
        \PY{n}{sample} \PY{o}{=} \PY{n}{entry}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{`}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k}{for} \PY{n}{snp} \PY{o+ow}{in} \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
            \PY{n}{ruby\PYZus{}grade} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{ruby\PYZus{}grade}\PY{p}{,} \PY{n}{ruby}\PY{p}{(}\PY{n}{sample}\PY{p}{,} \PY{n}{snp}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
        \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}ruby\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{n}{ruby\PYZus{}grade}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{statistical-tests-for-computer-metrics}{%
\subsection{Statistical tests for computer
metrics}\label{statistical-tests-for-computer-metrics}}

    Here we split all grades for all metrics into a dictionary of
dictionaries that has metric and model as keys and list of all grades as
a value. We then use it to run Wilcoxon signed-rank test

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{206}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{defaultdict}
\PY{n}{split\PYZus{}grades} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
        \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
            \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{metric}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{split\PYZus{}grades}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
defaultdict(<class 'dict'>, \{'bleu': \{'baseline': [0.0, 0.4566, 0.0, 0.0, 0.0,
0.5052, 0.0, 0.4809, 0.0, 0.0, 0.0374, 0.0, 0.327, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0738, 0.0, 0.2681, 0.0, 0.0, 0.0, 0.0, 0.4532, 0.0, 0.443, 0.0, 0.0, 0.0, 0.0,
0.0, 0.3226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0548, 0.0915, 0.0, 0.2491, 0.226, 0.0,
0.0, 0.0, 0.2075, 0.0, 0.2575, 0.3116, 0.471, 0.3324, 0.0, 0.0, 0.0, 0.2042,
0.0, 0.0, 0.1443, 0.0, 0.2179, 0.0, 0.0, 0.0, 0.0, 0.0934, 0.0, 0.0, 0.0, 0.0,
0.0, 0.1063, 0.0, 0.0967, 0.0, 0.0, 0.2201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.1234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1514, 0.0, 0.4054, 0.0,
0.2685, 0.1824, 0.0, 0.0, 0.4161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1403, 0.2287,
0.3661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1514,
0.0, 0.5309, 0.0, 0.3672, 0.1713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1833, 0.0, 0.0,
0.144, 0.0, 0.0, 0.0, 0.0, 0.0871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.2176, 0.2256, 0.0, 0.0, 0.0571, 0.0, 0.2568, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.3725, 0.0, 0.2339, 0.3136, 0.0, 0.2256, 0.2915, 0.0,
0.0, 0.0, 0.1786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.186, 0.0, 0.2765, 0.0, 0.0, 0.0, 0.4231, 0.4121, 0.0, 0.0, 0.1972, 0.205,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1225, 0.0, 0.079, 0.1328, 0.0, 0.256, 0.5086,
0.0, 0.0, 0.2167, 0.0, 0.0, 0.0, 0.4777, 0.0, 0.0968, 0.0, 0.2393, 0.0, 0.0,
0.0, 0.4433, 0.0, 0.0657, 0.0, 0.306, 0.5072, 0.1641, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1037, 0.0, 0.0, 0.0, 0.2069, 0.0, 0.2758, 0.0,
0.0, 0.0, 0.2652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1383,
0.0, 0.0, 0.0, 0.0, 0.0, 0.2485, 0.2597, 0.0, 0.0, 0.0, 0.2127, 0.0, 0.0,
0.1156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0911, 0.0, 0.0, 0.0, 0.2129, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5019, 0.1603, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.1843, 0.0, 0.1821, 0.3508, 0.1428, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.2307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2205, 0.2053, 0.0, 0.0,
0.0, 0.1404, 0.0, 0.4981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2805, 0.1961, 0.0,
0.468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031, 0.0, 0.2209, 0.3506, 0.0, 0.0,
0.0, 0.0, 0.0, 0.6931, 0.425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5125, 0.0, 0.0, 0.0833, 0.0, 0.1462,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.147, 0.0, 0.0, 0.0, 0.0, 0.1545,
0.0, 0.0, 0.1758, 0.0, 0.1645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.3075, 0.0, 0.0, 0.0, 0.256, 0.0, 0.0, 0.1943, 0.1891, 0.0,
0.5224, 0.0, 0.4002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1722, 0.0, 0.0, 0.0, 0.0],
'tranx-annot': [0.0, 0.51, 0.3744, 0.0, 0.2676, 0.7655, 0.6114, 0.5632, 0.0,
0.0, 0.0, 0.0, 0.3579, 0.2694, 0.2178, 0.0, 0.4111, 0.3128, 0.6803, 0.0, 0.2145,
0.4018, 0.0, 1.0, 0.7272, 1.0, 0.0, 0.4609, 0.0, 0.0, 0.4796, 0.0, 0.3726,
0.2397, 0.0, 0.0, 0.2435, 0.0, 0.1883, 0.4346, 0.0, 0.1594, 0.3997, 0.2087,
0.3724, 0.0, 0.0, 0.0, 0.7635, 0.1945, 0.7399, 0.5451, 0.3324, 0.0, 0.0, 0.2246,
0.2135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1633, 0.3794, 0.0,
0.1706, 0.0, 0.0, 0.5126, 0.0, 0.2867, 0.3415, 0.2478, 0.1366, 0.6776, 0.0,
0.3772, 0.0, 0.2277, 0.4572, 0.5608, 0.0, 0.2503, 0.0, 0.3653, 0.0, 0.0, 0.153,
0.9373, 0.3575, 0.5535, 0.6592, 0.4654, 0.0, 0.0908, 0.0032, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.1997, 0.1228, 0.5, 0.0, 0.2418, 0.1463, 0.2383, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2022, 0.1897, 0.0, 0.0, 0.0, 0.0, 0.2865,
0.3209, 0.2469, 0.0, 0.0, 0.0, 0.0, 0.5202, 0.0, 0.2476, 0.3289, 1.0, 0.0,
0.7772, 0.0, 0.0, 0.0, 0.3053, 0.0, 0.3005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3083,
0.0, 0.4544, 0.1598, 0.4086, 0.2785, 0.0, 0.301, 0.0, 0.8017, 0.1133, 0.4011,
0.3181, 0.0, 0.0, 0.0, 0.3608, 0.2833, 0.0, 0.0, 0.5015, 0.162, 0.3457, 0.0,
0.6683, 0.4728, 0.261, 0.2144, 0.0, 0.0, 0.0, 0.5934, 0.0, 0.2019, 0.0, 0.4705,
0.0, 0.7692, 0.4434, 0.8091, 0.0, 0.0, 0.2213, 0.0, 0.0, 0.2216, 0.0, 0.0, 0.0,
0.0, 0.0, 0.1982, 0.1483, 0.1514, 0.0, 0.4632, 0.1776, 0.2031, 0.0, 0.1955,
0.5411, 0.0, 0.0, 0.4763, 0.0, 0.3022, 0.3666, 0.6082, 0.2611, 0.0, 0.0257,
0.25, 0.0, 0.267, 0.0172, 0.226, 0.0, 0.2159, 0.7009, 0.0, 0.2163, 0.5717, 0.0,
0.0549, 0.0, 0.0, 0.0, 0.2968, 0.8948, 0.5835, 0.0, 0.2671, 0.3284, 0.0, 0.4423,
0.0, 0.0, 0.0, 0.0672, 0.1677, 0.4458, 0.4362, 0.4767, 0.0, 0.3749, 0.2566, 0.0,
0.1194, 0.0, 0.0, 0.0, 0.0, 0.2076, 0.0, 0.1964, 0.0, 0.0, 0.0, 0.0, 0.0,
0.6263, 0.0, 0.0, 0.4536, 0.0, 0.6505, 0.0, 0.0, 0.9355, 0.8564, 0.6606, 0.6026,
0.0, 0.0, 0.0, 0.0, 0.3418, 0.0, 0.3881, 0.0, 0.0, 0.0, 0.2727, 0.0, 0.0,
0.6931, 0.0, 0.1145, 0.0967, 0.2613, 0.7252, 0.3659, 0.3268, 0.3397, 0.0,
0.7827, 0.0, 0.0, 0.4349, 0.0, 0.273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.3457, 0.1857, 0.0, 0.1881, 0.5019, 0.0, 1.0, 0.0, 0.0, 0.3619, 0.0,
0.2254, 0.0, 0.091, 0.0, 0.5, 0.0, 0.0, 0.0, 0.2489, 0.0, 0.5465, 0.5492, 0.0,
0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0525, 0.6105, 0.1518, 0.0, 0.1459,
0.0, 0.3013, 0.2948, 0.286, 0.2264, 0.0, 0.2778, 0.0, 0.0, 0.2009, 0.0, 0.4222,
0.0, 0.1662, 0.0554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5191, 0.3814, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.5266, 0.7239, 0.3214, 0.1932, 0.6409, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.1889, 0.0, 0.38, 0.0, 0.0, 0.0, 0.0, 0.2221, 0.0, 0.0, 0.0,
0.2631, 0.1911, 0.2847, 0.0, 0.0, 0.238, 0.0, 0.0, 0.246, 0.5555, 0.1528, 0.0,
0.0, 0.0, 0.0, 0.0, 0.3781, 0.0, 0.0, 0.0, 0.0, 0.7519, 0.0, 0.0, 0.0, 0.2394,
0.0, 0.1097, 0.0, 0.0, 0.3876, 0.0, 0.1308, 0.0, 0.0, 0.1784, 0.1744, 0.3888,
0.0824, 0.2654, 0.0, 0.4944, 0.0, 0.3083, 0.488, 0.3128, 0.0, 1.0, 0.0, 0.2028,
0.0, 0.0, 0.0, 0.0, 0.1791, 0.7598, 0.0, 0.0], 'best-tranx': [0.0, 0.3118, 0.0,
0.0, 0.4739, 0.0597, 0.4723, 1.0, 0.0, 0.0, 0.2621, 0.2516, 0.3551, 0.4694,
0.1832, 0.1849, 0.5946, 0.0, 0.0, 0.0, 0.0, 0.3571, 0.0, 1.0, 0.7272, 1.0, 0.0,
0.459, 0.0, 0.0488, 0.2958, 0.0, 0.0, 0.0, 0.0, 0.4273, 0.2435, 0.1358, 0.0,
0.0, 0.1211, 0.0, 0.0, 0.2333, 0.0, 0.0, 0.5219, 0.3027, 0.7635, 0.3095, 0.4576,
0.5976, 0.1173, 0.0, 0.0, 0.2931, 0.2168, 0.0, 0.0, 0.0, 0.3655, 0.0, 0.5076,
0.0, 0.0, 0.0, 0.1318, 0.4237, 0.2782, 0.0, 0.0, 0.1563, 0.3313, 0.0, 0.2242,
0.1987, 0.0, 0.1441, 0.5181, 0.0, 0.0, 0.0, 0.2688, 0.7249, 0.3882, 0.0, 0.0,
0.0, 0.2475, 0.0, 0.0, 0.0, 0.9373, 0.3357, 0.6324, 0.6592, 0.5187, 0.1879,
0.4103, 0.0, 0.0, 0.3563, 0.4261, 0.197, 0.0, 0.0, 0.1974, 0.0, 0.3109, 0.0,
0.1398, 0.0, 0.2785, 0.2918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3782, 0.0, 0.0, 0.5634,
0.1415, 0.2138, 0.0, 0.4138, 0.0, 0.0, 0.2798, 0.0, 0.0, 0.5081, 0.0, 0.0, 0.0,
0.2245, 0.1674, 0.3967, 0.3911, 0.2691, 0.0, 0.1318, 0.0, 0.0, 0.0924, 0.0884,
0.0, 0.3671, 0.0, 0.2033, 0.2045, 0.0, 0.0, 0.6953, 0.0, 0.7748, 0.1469, 0.2573,
0.33, 0.1419, 0.1578, 0.0, 0.7831, 0.0, 0.4011, 0.287, 0.0, 0.0, 0.0, 0.3799,
0.0, 0.0, 0.0, 0.2843, 0.162, 0.0, 0.0, 0.3239, 0.0, 0.3636, 0.1082, 0.0, 0.0,
0.0, 0.4366, 0.4159, 0.3725, 0.1821, 0.3218, 0.0, 0.7293, 0.4244, 0.7744, 0.0,
0.3099, 0.1266, 0.0, 0.1245, 0.4625, 0.0, 0.0, 0.0, 0.0, 0.3165, 0.2871, 0.1596,
0.0693, 0.0, 0.4632, 0.1817, 0.2972, 0.0, 0.1955, 0.5411, 0.0, 0.2546, 0.2831,
0.2966, 0.2699, 0.0, 0.5145, 0.3967, 1.0, 0.0, 0.0, 0.0, 0.3842, 0.0, 0.191,
0.0, 0.3044, 0.0, 0.0, 0.0, 0.5788, 0.0, 0.1632, 0.0738, 0.3482, 0.0, 0.0,
0.6209, 0.7966, 0.0, 0.2704, 0.2984, 0.3223, 0.7668, 0.2574, 0.0, 0.0, 0.1848,
0.3032, 0.0, 0.2876, 0.3553, 0.091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.2158, 0.7598, 0.2114, 0.298, 0.0, 0.1565, 0.0, 0.0, 0.8091, 1.0, 0.5882,
0.6612, 0.0, 0.4777, 0.0, 0.0, 0.4815, 0.4531, 0.2136, 0.3806, 0.6725, 0.0,
0.6913, 0.0, 0.1767, 0.0, 0.4217, 0.0, 0.0, 0.1672, 0.493, 0.0, 0.4016, 0.0,
0.0, 0.0, 0.3821, 0.2264, 0.9221, 0.1542, 0.3154, 0.0, 0.0, 0.5399, 0.2281,
0.1973, 0.0, 0.0, 0.273, 0.0561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.5448, 0.2915, 0.0, 0.1634, 0.752, 0.2192, 1.0, 0.0738, 0.1695, 0.0, 0.0,
0.4444, 1.0, 0.0, 0.0, 0.0, 0.5659, 0.0, 0.1274, 0.2489, 0.8318, 0.5465, 0.7325,
0.0, 0.0796, 1.0, 1.0, 1.0, 1.0, 0.4111, 0.4111, 0.2227, 0.0642, 0.3146, 0.4917,
0.0, 0.5357, 0.0, 0.8907, 0.3638, 0.0, 0.2081, 0.0, 0.1186, 0.2349, 0.0, 0.1705,
0.0647, 0.0, 0.0, 0.0, 0.0554, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3971, 0.8172,
0.0, 0.0, 0.0, 0.0, 0.5355, 0.5781, 0.5266, 0.7239, 0.2885, 0.5118, 0.3269, 0.0,
0.0, 0.0, 0.7633, 0.0, 0.0, 0.141, 0.5751, 0.0, 0.2639, 0.0, 0.1989, 0.0, 0.0,
0.2221, 0.0, 0.0, 0.3082, 0.3264, 0.3557, 0.4021, 0.1504, 0.0, 1.0, 0.0, 0.0,
0.0, 0.5157, 0.1528, 0.1674, 0.0, 0.3864, 0.0, 0.0, 0.3781, 0.3408, 0.0, 0.0,
0.0, 1.0, 0.2479, 0.1258, 0.0, 0.6695, 0.0, 0.1611, 0.0, 0.0, 0.0, 0.5311, 0.0,
0.0, 0.2768, 0.2906, 0.2592, 0.3888, 0.0824, 0.0627, 0.0, 0.3307, 0.1531,
0.1519, 0.4226, 0.0, 0.0, 1.0, 0.0, 0.0, 0.716, 0.0, 0.0, 0.0648, 0.2106,
0.3646, 0.0, 0.0], 'best-tranx-rerank': [0.0, 0.3278, 0.0, 0.0, 0.4739, 0.0597,
0.4223, 1.0, 0.0, 0.0, 0.0, 0.2516, 0.784, 0.4694, 0.1832, 0.1849, 0.5946, 0.0,
0.1089, 0.0, 0.3387, 0.3571, 0.0, 1.0, 0.7272, 1.0, 0.0, 0.564, 0.0, 0.0488,
0.2958, 0.0, 0.0, 0.0, 0.0, 0.8633, 0.2435, 0.0, 0.2849, 0.0, 0.1211, 0.0, 0.0,
0.2333, 0.3724, 0.0, 0.5219, 0.3027, 0.7635, 0.3095, 0.4765, 0.5976, 0.1173,
0.0, 0.0, 0.2931, 0.2676, 0.0, 0.0, 0.0, 0.3798, 0.0, 0.5076, 0.0, 0.0, 0.0,
0.1318, 0.4237, 0.2782, 0.0, 0.0, 0.1563, 0.306, 0.0, 0.2242, 0.1987, 0.0,
0.1441, 0.3968, 0.0, 0.0, 0.0, 0.2688, 0.7249, 0.3882, 0.0, 0.0, 0.0, 0.2475,
0.0, 0.0, 0.0, 0.9373, 0.3357, 0.6324, 0.6592, 0.5187, 0.1879, 0.4103, 0.2887,
0.0, 0.3563, 0.4261, 0.197, 0.1449, 0.0, 0.1974, 0.0, 0.2853, 0.0, 0.1398, 0.0,
0.0, 0.2918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3782, 0.0, 0.0, 0.5634, 0.1415, 0.1773,
0.0, 0.4138, 0.0, 0.0, 0.2798, 0.0, 0.0, 0.5081, 0.0, 0.0, 0.0, 0.2245, 0.1674,
0.2725, 0.3911, 0.2691, 0.0, 0.3228, 0.0, 0.0, 0.0924, 0.3714, 0.0, 0.3671, 0.0,
0.2033, 0.2045, 0.0, 0.0, 0.152, 0.0, 0.7748, 0.1469, 0.2573, 0.3537, 0.292,
0.1578, 0.0, 0.4499, 0.3662, 0.4011, 0.287, 0.4643, 0.0, 0.0, 0.3799, 0.0, 0.0,
0.0, 0.3831, 0.162, 0.2346, 0.0, 0.3239, 0.0, 0.3636, 0.1082, 0.0, 0.0, 0.0,
0.4366, 0.1291, 0.3725, 0.3479, 0.6841, 0.0, 0.7293, 0.4244, 0.7744, 0.1197,
0.3099, 0.2483, 0.0, 0.1245, 0.4643, 0.0, 0.0, 0.0, 0.0, 0.2154, 0.2487, 0.3701,
0.0782, 0.0, 0.4632, 0.1817, 0.2972, 0.0, 0.1955, 0.5411, 0.0, 0.2546, 0.2831,
0.2966, 0.2699, 0.0, 0.5145, 0.3967, 1.0, 0.0, 0.0, 0.0, 0.0, 0.103, 0.191,
0.2756, 0.3044, 0.3267, 0.0, 0.0, 0.424, 0.0, 0.1116, 0.3187, 0.3482, 0.3522,
0.0, 0.6209, 0.7966, 0.1608, 0.2704, 0.2984, 0.3223, 0.7668, 0.1955, 0.0, 0.0,
0.1035, 0.3032, 0.7505, 0.3254, 0.3553, 0.0, 0.2033, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.7598, 0.2114, 0.2388, 0.0, 0.1131, 0.0, 0.0, 0.8091, 1.0,
0.5934, 0.284, 0.0, 0.2168, 0.0, 0.0, 0.2937, 0.3026, 0.2136, 0.0, 0.32, 0.0,
0.6913, 0.0, 0.1767, 0.0, 0.4301, 0.0, 0.0, 0.1672, 0.493, 0.0, 0.0, 0.0, 0.0,
0.6885, 0.3821, 0.2264, 0.9221, 0.3015, 0.3154, 0.304, 0.0, 0.5399, 0.2281,
0.1973, 0.1108, 0.0, 0.273, 0.1261, 0.2778, 0.2778, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.5448, 0.2915, 0.0, 0.1634, 0.752, 0.2192, 1.0, 0.0, 0.1695, 0.0,
0.0, 0.5796, 1.0, 0.0, 0.0, 0.0, 0.5659, 0.0, 0.0, 0.2489, 0.8318, 0.5465,
0.7325, 0.0, 0.0674, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2227, 0.0642, 0.4799,
0.4917, 0.0, 0.5357, 0.4631, 0.8907, 0.3638, 0.3632, 0.2081, 0.0, 0.2907,
0.2349, 0.0, 0.0, 0.0647, 0.0, 0.0, 0.0, 0.0554, 0.4104, 0.0, 0.0, 0.0, 0.0,
0.0, 0.5482, 0.8172, 0.0, 0.0, 0.0, 0.0, 0.5355, 0.5781, 0.5266, 0.7239, 0.2885,
0.5118, 0.3269, 0.0, 0.0, 0.1659, 1.0, 0.0, 0.0, 0.5877, 0.5751, 0.0, 0.2639,
0.0, 0.167, 0.0, 0.0, 0.2221, 0.0, 0.234, 0.4617, 0.3264, 0.4302, 0.4021,
0.1342, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8409, 0.1528, 0.061, 0.0, 0.0, 0.0, 0.0,
0.3781, 0.3408, 0.0, 0.0, 0.0, 1.0, 0.2479, 0.1258, 0.0, 0.6695, 0.1937, 0.2459,
0.0, 0.0, 0.0, 0.5311, 0.0, 0.0, 0.2768, 0.2906, 0.2592, 0.3888, 0.0824, 0.0627,
0.0, 0.3307, 0.4331, 0.2001, 0.4226, 0.0, 0.0, 0.2765, 0.0, 0.0, 0.716, 0.0,
0.0, 0.1522, 0.2106, 0.3646, 0.1089, 0.0]\}, 'rougel': \{'baseline': [0.4, 0.6829,
0.4138, 0.1194, 0.1951, 0.6222, 0.3, 0.7179, 0.2128, 0.3846, 0.375, 0.0556,
0.6452, 0.2941, 0.3846, 0.25, 0.4, 0.3448, 0.2333, 0.2308, 0.6667, 0.3333, 0.4,
0.3111, 0.4118, 0.7368, 0.0984, 0.75, 0.3158, 0.2712, 0.4762, 0.15, 0.381,
0.5882, 0.2857, 0.2069, 0.4242, 0.3243, 0.5385, 0.3448, 0.4848, 0.3243, 0.619,
0.5556, 0.3571, 0.16, 0.4444, 0.6, 0.2899, 0.6038, 0.5, 0.6571, 0.6667, 0.4138,
0.1875, 0.5, 0.449, 0.2381, 0.2727, 0.5294, 0.25, 0.5641, 0.1613, 0.0, 0.7143,
0.3158, 0.4762, 0.3333, 0.381, 0.3846, 0.25, 0.4651, 0.3951, 0.2667, 0.4848,
0.3243, 0.6286, 0.5714, 0.122, 0.4286, 0.1333, 0.4545, 0.375, 0.5, 0.24, 0.5,
0.4762, 0.5405, 0.1379, 0.2642, 0.3673, 0.2963, 0.4262, 0.5263, 0.4324, 0.5143,
0.5763, 0.5294, 0.6154, 0.5652, 0.2286, 0.4375, 0.7143, 0.3871, 0.4375, 0.4375,
0.3243, 0.3265, 0.3333, 0.3033, 0.4762, 0.7273, 0.5641, 0.5217, 0.3902, 0.4545,
0.56, 0.4348, 0.1111, 0.2848, 0.0, 0.24, 0.303, 0.4706, 0.303, 0.1765, 0.5862,
0.0714, 0.3913, 0.5, 0.4, 0.5405, 0.0, 0.0, 0.3333, 0.25, 0.4286, 0.5294,
0.3636, 0.4706, 0.4348, 0.5, 0.7368, 0.3846, 0.6316, 0.5882, 0.4348, 0.2609,
0.5333, 0.5625, 0.3846, 0.4828, 0.7333, 0.1935, 0.5263, 0.25, 0.2778, 0.2143,
0.3448, 0.2597, 0.2857, 0.2857, 0.44, 0.5316, 0.4348, 0.5641, 0.5946, 0.4167,
0.3636, 0.2626, 0.3182, 0.2857, 0.4103, 0.2667, 0.5833, 0.5217, 0.4, 0.5714,
0.36, 0.381, 0.5789, 0.4912, 0.4286, 0.4324, 0.1176, 0.3636, 0.5161, 0.7222,
0.3571, 0.4242, 0.5625, 0.6667, 0.5556, 0.5882, 0.2759, 0.4667, 0.25, 0.6111,
0.4667, 0.5143, 0.3158, 0.0, 0.303, 0.32, 0.381, 0.2034, 0.4091, 0.3273, 0.4138,
0.3913, 0.4167, 0.4667, 0.3333, 0.4828, 0.7143, 0.5, 0.4, 0.6897, 0.72, 0.2353,
0.3448, 0.4286, 0.5116, 0.25, 0.4444, 0.4865, 0.0698, 0.4286, 0.1852, 0.4815,
0.6, 0.4167, 0.4906, 0.6, 0.6207, 0.7302, 0.25, 0.3396, 0.4375, 0.3871, 0.0,
0.4516, 0.8293, 0.3429, 0.4651, 0.359, 0.6071, 0.3415, 0.0, 0.4681, 0.6522,
0.2778, 0.3077, 0.4615, 0.5789, 0.7273, 0.5185, 0.4364, 0.3333, 0.4737, 0.5,
0.3889, 0.2759, 0.1867, 0.087, 0.4242, 0.4, 0.5455, 0.5238, 0.3226, 0.5714,
0.2667, 0.6667, 0.6452, 0.6667, 0.5, 0.4444, 0.5075, 0.6122, 0.2887, 0.1111,
0.2564, 0.4364, 0.3519, 0.4118, 0.2069, 0.3882, 0.3333, 0.2222, 0.3333, 0.4898,
0.3571, 0.0, 0.24, 0.5, 0.0811, 0.5806, 0.6316, 0.2778, 0.4286, 0.4375, 0.5,
0.3158, 0.2022, 0.3492, 0.2414, 0.3333, 0.4571, 0.2759, 0.26, 0.5581, 0.7111,
0.4138, 0.5, 0.4091, 0.3704, 0.2353, 0.5111, 0.0, 0.1818, 0.0, 0.5333, 0.24,
0.3889, 0.1739, 0.4062, 0.3243, 0.25, 0.4848, 0.7568, 0.4898, 0.2609, 0.4848,
0.2424, 0.5, 0.3636, 0.3333, 0.2105, 0.5882, 0.4444, 0.5217, 0.7273, 0.4828,
0.2581, 0.4, 0.4643, 0.4762, 0.1667, 0.3571, 0.3492, 0.6222, 0.1818, 0.0,
0.1667, 0.0, 0.1333, 0.5455, 0.4776, 0.2128, 0.4651, 0.5714, 0.6154, 0.4615,
0.5458, 0.48, 0.2703, 0.4878, 0.3478, 0.4444, 0.4667, 0.5882, 0.5217, 0.3137,
0.7442, 0.3529, 0.4167, 0.1639, 0.4444, 0.0, 0.1538, 0.3704, 0.32, 0.2222,
0.6364, 0.75, 0.0, 0.2105, 0.0, 0.5185, 0.6429, 0.88, 0.7692, 0.3462, 0.2564,
0.6286, 0.4, 0.2963, 0.3448, 0.3125, 0.3077, 0.3226, 0.4, 0.3478, 0.4873,
0.6154, 0.1652, 0.3636, 0.1961, 0.2857, 0.3077, 0.7692, 0.5, 0.3243, 0.4783,
0.3902, 0.4878, 0.3265, 0.4103, 0.3607, 0.0238, 0.2963, 0.4, 0.375, 0.1875,
0.3158, 0.5385, 0.4651, 0.1644, 0.2308, 0.3871, 0.5, 0.4, 0.3889, 0.5128,
0.2105, 0.3818, 0.2703, 0.4, 0.3158, 0.5532, 0.3429, 0.3288, 0.3636, 0.3077,
0.5714, 0.4286, 0.3529, 0.3226, 0.1818, 0.7692, 0.4615, 0.4762, 0.4, 0.5926,
0.6, 0.5714, 0.383, 0.5, 0.3077, 0.6875, 0.2353, 0.6364, 0.45, 0.4615, 0.4286,
0.4138, 0.2424, 0.4583, 0.5143, 0.6316, 0.3902, 0.6667], 'tranx-annot': [0.5,
0.7692, 0.6452, 0.3137, 0.5581, 0.75, 0.75, 0.8293, 0.4444, 0.4375, 0.3529,
0.4375, 0.5854, 0.6667, 0.6207, 0.3, 0.6667, 0.6486, 0.8571, 0.2821, 0.6,
0.6857, 0.4, 1.0, 0.8571, 1.0, 0.172, 0.6275, 0.5714, 0.3214, 0.7308, 0.2581,
0.7778, 0.5517, 0.2, 0.5263, 0.6207, 0.4314, 0.4348, 0.7059, 0.2759, 0.5806,
0.6667, 0.64, 0.6667, 0.4667, 0.5641, 0.3571, 0.8372, 0.5405, 0.8814, 0.7541,
0.6667, 0.4667, 0.3, 0.5185, 0.4889, 0.2609, 0.1053, 0.5, 0.5263, 0.3243,
0.4615, 0.2857, 0.3333, 0.1778, 0.5909, 0.678, 0.5405, 0.4, 0.3704, 0.2, 0.717,
0.4516, 0.55, 0.6486, 0.566, 0.4681, 0.8511, 0.3158, 0.68, 0.3182, 0.5909, 0.72,
0.7353, 0.5405, 0.6, 0.4878, 0.56, 0.1379, 0.4314, 0.55, 0.9737, 0.6061, 0.7917,
0.9231, 0.6744, 0.5, 0.4444, 0.2703, 0.5, 0.4848, 0.7333, 0.4667, 0.4, 0.5789,
0.4651, 0.6538, 0.4828, 0.4674, 0.6875, 0.7143, 0.45, 0.625, 0.5909, 0.3529,
0.4324, 0.3158, 0.5714, 0.3804, 0.5714, 0.4762, 0.4898, 0.5128, 0.5116, 0.3333,
0.3137, 0.4211, 0.0, 0.7333, 0.6452, 0.45, 0.3333, 0.4286, 0.2727, 0.6087,
0.7619, 0.5263, 0.45, 0.6486, 1.0, 0.4848, 0.9, 0.4444, 0.4444, 0.44, 0.5862,
0.1622, 0.6667, 0.5128, 0.4615, 0.5333, 0.3158, 0.3333, 0.72, 0.3, 0.6842,
0.6111, 0.75, 0.5714, 0.4889, 0.6818, 0.5778, 0.8785, 0.4286, 0.8333, 0.6667,
0.3607, 0.5366, 0.3911, 0.5854, 0.65, 0.3043, 0.5, 0.7568, 0.6364, 0.7, 0.5946,
0.8267, 0.7407, 0.5625, 0.4762, 0.4167, 0.4138, 0.3333, 0.8333, 0.3, 0.5,
0.7143, 0.8, 0.4138, 0.9167, 0.7429, 0.9286, 0.4167, 0.3125, 0.5417, 0.5854,
0.4286, 0.5306, 0.5714, 0.5714, 0.4615, 0.3889, 0.5833, 0.5532, 0.55, 0.5714,
0.2727, 0.7619, 0.5091, 0.4211, 0.32, 0.4828, 0.8571, 0.6667, 0.4348, 0.75,
0.7778, 0.4138, 0.6061, 0.7568, 0.4333, 0.5714, 0.4, 0.6667, 0.3636, 0.5417,
0.3529, 0.56, 0.5714, 0.5106, 0.84, 0.1765, 0.6154, 0.7302, 0.5333, 0.449, 0.5,
0.48, 0.5185, 0.5714, 0.9474, 0.7619, 0.4898, 0.7742, 0.7083, 0.5333, 0.7179,
0.5581, 0.5455, 0.4706, 0.32, 0.6087, 0.8, 0.7333, 0.8, 0.5333, 0.7111, 0.6667,
0.4906, 0.4444, 0.3871, 0.3606, 0.3808, 0.4444, 0.7059, 0.6667, 0.5098, 0.3333,
0.5455, 0.4878, 0.5143, 0.4865, 0.8, 0.7059, 0.4848, 0.6747, 0.5143, 0.7955,
0.1765, 0.3478, 0.9655, 0.9032, 0.9286, 0.8, 0.3572, 0.4, 0.4, 0.3509, 0.6667,
0.3478, 0.7027, 0.3478, 0.5909, 0.4, 0.5714, 0.5, 0.4828, 0.88, 0.5833, 0.4571,
0.4545, 0.549, 0.8571, 0.7143, 0.5946, 0.7143, 0.4118, 0.9167, 0.5333, 0.4878,
0.8148, 0.24, 0.4762, 0.4444, 0.1538, 0.147, 0.1538, 0.8333, 0.8333, 0.8333,
0.4706, 0.1818, 0.3158, 0.6429, 0.6512, 0.3636, 0.7333, 0.7568, 0.3529, 1.0,
0.4545, 0.5238, 0.7273, 0.303, 0.5882, 0.3077, 0.566, 0.3, 0.875, 0.6923,
0.5455, 0.3415, 0.5854, 0.3929, 0.7733, 0.7246, 0.4545, 0.3562, 1.0, 1.0, 0.4,
0.4, 0.7273, 0.7273, 0.5833, 0.3871, 0.7778, 0.5143, 0.4444, 0.6154, 0.5, 0.539,
0.7097, 0.6667, 0.6875, 0.2308, 0.5, 0.4, 0.5, 0.5861, 0.3256, 0.5789, 0.5714,
0.5, 0.4324, 0.2051, 0.1111, 0.5714, 0.3846, 0.2083, 0.25, 0.6939, 0.6, 0.5455,
0.4286, 0.5455, 0.4138, 0.72, 0.6667, 0.8462, 0.9, 0.7273, 0.4865, 0.8571, 0.0,
0.4118, 0.4667, 0.6154, 0.4571, 0.5, 0.6, 0.4566, 0.6667, 0.4958, 0.5, 0.3673,
0.3111, 0.6452, 0.6061, 0.2069, 0.2162, 0.25, 0.4848, 0.5909, 0.6154, 0.5,
0.2927, 0.449, 0.6, 0.3478, 0.5, 0.8889, 0.4348, 0.3182, 0.5294, 0.5806, 0.5517,
0.4375, 0.6875, 0.5854, 0.3158, 0.359, 0.4186, 0.8214, 0.4375, 0.2286, 0.3478,
0.7368, 0.5, 0.5, 0.4706, 0.4444, 0.6452, 0.4, 0.4828, 0.2222, 0.6047, 0.5,
0.5882, 0.7, 0.4865, 0.5238, 0.5217, 0.7619, 0.3934, 0.6957, 0.7692, 0.7179,
0.2069, 1.0, 0.45, 0.6, 0.5161, 0.5, 0.0625, 0.2979, 0.4516, 0.8889, 0.4571,
0.381], 'best-tranx': [0.5833, 0.6875, 0.5517, 0.4583, 0.75, 0.3939, 0.6774,
1.0, 0.2941, 0.3846, 0.6429, 0.5161, 0.7333, 0.6875, 0.4138, 0.4828, 0.875,
0.48, 0.375, 0.2143, 0.5217, 0.7, 0.3571, 1.0, 0.8571, 1.0, 0.129, 0.6809,
0.625, 0.3448, 0.6222, 0.2759, 0.6415, 0.6087, 0.5263, 0.7778, 0.6207, 0.4186,
0.3684, 0.4, 0.4615, 0.3333, 0.4444, 0.5938, 0.3871, 0.375, 0.7568, 0.4615,
0.8372, 0.6316, 0.6744, 0.807, 0.4828, 0.64, 0.4324, 0.6, 0.5238, 0.2439,
0.4211, 0.4865, 0.6122, 0.4091, 0.72, 0.4348, 0.5, 0.2, 0.5238, 0.7018, 0.4286,
0.4211, 0.5455, 0.4865, 0.6, 0.1569, 0.5714, 0.6129, 0.6364, 0.4762, 0.7083,
0.4706, 0.449, 0.3684, 0.6538, 0.9167, 0.5814, 0.4848, 0.25, 0.4103, 0.5217,
0.2353, 0.4727, 0.6154, 0.9737, 0.7692, 0.8205, 0.9231, 0.7179, 0.5946, 0.7018,
0.36, 0.5714, 0.7333, 0.8, 0.6087, 0.2778, 0.4138, 0.4444, 0.4528, 0.6857,
0.2699, 0.4231, 0.5405, 0.6275, 0.5946, 0.4615, 0.3243, 0.6923, 0.2857, 0.4211,
0.5152, 0.4211, 0.4444, 0.8108, 0.5455, 0.5, 0.5, 0.6, 0.4706, 0.5366, 0.5556,
0.4, 0.3125, 0.8, 0.2857, 0.8571, 0.5333, 0.5143, 0.4375, 0.6154, 0.7568,
0.6316, 0.4848, 0.375, 0.2553, 0.2553, 0.4545, 0.3721, 0.3333, 0.6842, 0.4848,
0.5185, 0.4348, 0.3636, 0.4, 0.8182, 0.3846, 0.95, 0.6111, 0.5333, 0.7, 0.5143,
0.5143, 0.5, 0.8785, 0.3721, 0.8333, 0.7647, 0.5641, 0.4545, 0.3288, 0.6316,
0.3125, 0.375, 0.2712, 0.5, 0.6364, 0.5, 0.5333, 0.6415, 0.4, 0.5652, 0.3774,
0.375, 0.4118, 0.2264, 0.8, 0.7143, 0.7222, 0.4444, 0.5789, 0.3158, 0.8333,
0.6857, 0.8571, 0.3448, 0.6667, 0.4545, 0.6842, 0.4706, 0.7778, 0.5185, 0.5185,
0.375, 0.3, 0.6087, 0.5902, 0.5909, 0.4314, 0.4667, 0.7619, 0.52, 0.5517,
0.5714, 0.4828, 0.8571, 0.2143, 0.6452, 0.7407, 0.6897, 0.48, 0.3704, 0.8462,
0.68, 1.0, 0.5106, 0.2609, 0.3429, 0.6842, 0.2449, 0.6383, 0.4, 0.6122, 0.4167,
0.24, 0.4314, 0.7761, 0.5926, 0.6552, 0.3214, 0.7143, 0.6667, 0.3846, 0.9,
0.8889, 0.5405, 0.6061, 0.6531, 0.6364, 0.9375, 0.6047, 0.5333, 0.2857, 0.4912,
0.7037, 0.4375, 0.6977, 0.6667, 0.4231, 0.4118, 0.5714, 0.6512, 0.4737, 0.3704,
0.3854, 0.4048, 0.4444, 0.7059, 0.8333, 0.566, 0.5789, 0.7027, 0.6047, 0.4167,
0.4118, 0.9286, 1.0, 0.725, 0.7647, 0.5909, 0.6542, 0.1875, 0.2286, 0.6562,
0.6418, 0.4062, 0.5217, 0.6668, 0.4828, 0.8, 0.3111, 0.6667, 0.3158, 0.7619,
0.5833, 0.5909, 0.5946, 0.8205, 0.3125, 0.8, 0.4516, 0.4444, 0.5652, 0.8163,
0.7097, 0.9677, 0.6667, 0.6471, 0.4242, 0.3571, 0.7458, 0.68, 0.5882, 0.4516,
0.45, 0.4762, 0.4348, 0.3478, 0.3652, 0.3478, 0.1176, 0.1176, 0.1176, 0.4762,
0.45, 0.4444, 0.7857, 0.619, 0.3243, 0.6207, 0.85, 0.5778, 1.0, 0.5185, 0.6,
0.7059, 0.2632, 0.7059, 1.0, 0.383, 0.3333, 0.75, 0.7692, 0.5455, 0.5405,
0.5854, 0.9375, 0.7733, 0.8667, 0.5185, 0.3562, 1.0, 1.0, 1.0, 1.0, 0.7273,
0.7273, 0.6316, 0.4286, 0.6364, 0.6222, 0.5, 0.766, 0.4706, 0.6925, 0.6897,
0.5455, 0.6452, 0.303, 0.4242, 0.5366, 0.4167, 0.5357, 0.3913, 0.3529, 0.5333,
0.5185, 0.4324, 0.8, 0.4615, 0.625, 0.3077, 0.3729, 0.5185, 0.7083, 0.8837, 0.6,
0.6, 0.4615, 0.3704, 0.7407, 0.6667, 0.8462, 0.9, 0.7234, 0.8235, 0.56, 0.3902,
0.3684, 0.3784, 1.0, 0.4865, 0.25, 0.4444, 0.6674, 0.875, 0.3759, 0.5517,
0.5085, 0.4, 0.7143, 0.6061, 0.3784, 0.2667, 0.7018, 0.5714, 0.6667, 0.5714,
0.5778, 0.3529, 1.0, 0.5714, 0.4444, 0.7143, 0.7, 0.4348, 0.5714, 0.65, 0.7407,
0.5833, 0.4, 0.6875, 0.5909, 0.3889, 0.3636, 0.359, 1.0, 0.6087, 0.4762, 0.381,
0.88, 0.2609, 0.5205, 0.1818, 0.3846, 0.5, 0.8182, 0.5, 0.6923, 0.6842, 0.5714,
0.7, 0.7, 0.4865, 0.4118, 0.4444, 0.6842, 0.5205, 0.4545, 0.7368, 0.5806,
0.2667, 1.0, 0.3243, 0.5294, 0.8824, 0.6897, 0.1429, 0.4324, 0.5556, 0.7,
0.4091, 0.3333], 'best-tranx-rerank': [0.2667, 0.6429, 0.5517, 0.4583, 0.75,
0.3939, 0.6038, 1.0, 0.2941, 0.3077, 0.6, 0.5161, 0.95, 0.6875, 0.4138, 0.4828,
0.875, 0.48, 0.4706, 0.1967, 0.6667, 0.7, 0.3571, 1.0, 0.8571, 1.0, 0.129,
0.7586, 0.625, 0.3448, 0.6222, 0.2759, 0.5, 0.6087, 0.5263, 0.9412, 0.6207,
0.375, 0.5714, 0.4, 0.4615, 0.3333, 0.4706, 0.5938, 0.6667, 0.375, 0.7568,
0.4615, 0.8372, 0.6316, 0.6977, 0.807, 0.4828, 0.64, 0.4324, 0.6, 0.6275,
0.2439, 0.4211, 0.4865, 0.6122, 0.3226, 0.72, 0.4348, 0.5, 0.2, 0.5238, 0.7018,
0.4286, 0.4211, 0.5455, 0.4865, 0.439, 0.2222, 0.5714, 0.6129, 0.6111, 0.4762,
0.6667, 0.5161, 0.449, 0.3913, 0.6538, 0.9167, 0.5814, 0.4848, 0.25, 0.4103,
0.5217, 0.2353, 0.3922, 0.6154, 0.9737, 0.7692, 0.8205, 0.9231, 0.7179, 0.5946,
0.7018, 0.5, 0.5714, 0.7333, 0.8, 0.6087, 0.5333, 0.7059, 0.4444, 0.3704, 0.625,
0.4022, 0.4231, 0.5405, 0.3902, 0.5946, 0.4615, 0.4545, 0.6923, 0.2857, 0.4211,
0.5152, 0.4211, 0.4444, 0.8108, 0.5455, 0.4545, 0.5, 0.6, 0.4706, 0.5366,
0.5556, 0.4, 0.375, 0.8, 0.2857, 0.8571, 0.5333, 0.5143, 0.4375, 0.55, 0.7568,
0.6316, 0.4848, 0.7083, 0.5, 0.5, 0.4545, 0.7347, 0.3256, 0.6842, 0.4848,
0.5185, 0.4348, 0.7059, 0.4, 0.4865, 0.3846, 0.95, 0.6111, 0.5333, 0.7222,
0.6667, 0.5143, 0.5, 0.6275, 0.7451, 0.8333, 0.7647, 0.7727, 0.4545, 0.3288,
0.6316, 0.3125, 0.375, 0.2712, 0.6667, 0.6364, 0.5217, 0.5333, 0.6415, 0.4762,
0.5652, 0.3774, 0.375, 0.4737, 0.1818, 0.8, 0.56, 0.7222, 0.5926, 0.8667, 0.5,
0.8333, 0.6857, 0.8571, 0.4, 0.6667, 0.5833, 0.6842, 0.4706, 0.8, 0.5185,
0.5185, 0.375, 0.3, 0.5217, 0.6038, 0.6415, 0.4615, 0.4667, 0.7619, 0.52,
0.5517, 0.5714, 0.4828, 0.8571, 0.4286, 0.6452, 0.7407, 0.6897, 0.48, 0.2564,
0.8462, 0.68, 1.0, 0.5106, 0.2609, 0.3429, 0.5333, 0.4286, 0.6383, 0.72, 0.6122,
0.5333, 0.2857, 0.5143, 0.6667, 0.5926, 0.549, 0.5714, 0.7143, 0.75, 0.5714,
0.9, 0.8889, 0.6383, 0.6061, 0.6531, 0.6364, 0.9375, 0.5, 0.4762, 0.2857,
0.5106, 0.7037, 0.875, 0.6977, 0.6667, 0.3043, 0.4651, 0.6429, 0.6512, 0.4737,
0.3704, 0.3854, 0.4048, 0.4444, 0.4167, 0.8333, 0.566, 0.6111, 0.7027, 0.5,
0.4167, 0.4118, 0.9286, 1.0, 0.7246, 0.4655, 0.5641, 0.3743, 0.1875, 0.1875,
0.4693, 0.4859, 0.4062, 0.5, 0.6136, 0.64, 0.8, 0.3111, 0.6667, 0.3158, 0.65,
0.5833, 0.6667, 0.5946, 0.8205, 0.3448, 0.5333, 0.375, 0.4444, 0.9302, 0.8163,
0.7097, 0.9677, 0.6122, 0.6471, 0.7805, 0.3636, 0.7458, 0.68, 0.5882, 0.5532,
0.3571, 0.4762, 0.6154, 0.625, 0.5278, 0.3478, 0.1176, 0.1176, 0.1176, 0.5455,
0.5, 0.4444, 0.7857, 0.619, 0.3243, 0.6207, 0.85, 0.5778, 1.0, 0.4, 0.6, 0.7059,
0.2632, 0.7586, 1.0, 0.383, 0.3333, 0.75, 0.7692, 0.5455, 0.4762, 0.5854,
0.9375, 0.7733, 0.8667, 0.5185, 0.4412, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6316,
0.4286, 0.7, 0.6222, 0.5, 0.766, 0.7778, 0.6925, 0.6897, 0.72, 0.6452, 0.303,
0.6, 0.5366, 0.4865, 0.2401, 0.3913, 0.3529, 0.5333, 0.4667, 0.4324, 0.7097,
0.75, 0.625, 0.3529, 0.3729, 0.5185, 0.7805, 0.8837, 0.6, 0.6, 0.4615, 0.25,
0.7407, 0.6667, 0.8462, 0.9, 0.7234, 0.8235, 0.56, 0.3902, 0.3889, 0.6286, 1.0,
0.4865, 0.25, 0.8182, 0.6674, 0.875, 0.3759, 0.5517, 0.5614, 0.4, 0.7143,
0.6061, 0.3784, 0.4091, 0.7869, 0.5714, 0.6383, 0.5714, 0.7143, 0.3529, 1.0,
0.6364, 0.4444, 0.7143, 0.875, 0.4348, 0.3462, 0.65, 0.5, 0.4444, 0.4, 0.6875,
0.5909, 0.35, 0.5333, 0.359, 1.0, 0.6087, 0.4762, 0.381, 0.88, 0.4643, 0.5867,
0.1818, 0.3846, 0.7273, 0.8182, 0.5, 0.6923, 0.6842, 0.5714, 0.7, 0.7, 0.4865,
0.4118, 0.4444, 0.6842, 0.717, 0.5357, 0.7368, 0.5806, 0.2667, 0.5, 0.3243,
0.5294, 0.8824, 0.6897, 0.1429, 0.4615, 0.5556, 0.7, 0.4706, 0.6667]\}, 'meteor':
\{'baseline': [0.3003, 0.7871, 0.1911, 0.0707, 0.2329, 0.5045, 0.205, 0.6205,
0.1797, 0.2624, 0.1838, 0.0658, 0.4874, 0.1344, 0.1712, 0.1705, 0.5011, 0.2497,
0.1903, 0.1262, 0.5309, 0.1923, 0.1429, 0.1584, 0.2397, 0.6411, 0.0292, 0.605,
0.1807, 0.0973, 0.1825, 0.0781, 0.2, 0.5438, 0.1163, 0.4032, 0.3094, 0.1357,
0.3931, 0.2361, 0.2909, 0.2434, 0.5082, 0.422, 0.2657, 0.0826, 0.3093, 0.4749,
0.3139, 0.4206, 0.3849, 0.663, 0.5016, 0.2128, 0.1065, 0.3824, 0.285, 0.203,
0.1596, 0.3517, 0.1103, 0.4408, 0.0954, 0.0, 0.6, 0.1648, 0.188, 0.1583, 0.1504,
0.2416, 0.0852, 0.2615, 0.5239, 0.1408, 0.3237, 0.1408, 0.5124, 0.3278, 0.094,
0.3872, 0.0512, 0.1984, 0.1562, 0.3034, 0.2063, 0.2654, 0.2475, 0.3706, 0.0709,
0.1003, 0.1368, 0.1527, 0.2483, 0.4022, 0.3079, 0.5852, 0.4414, 0.2143, 0.4613,
0.359, 0.2301, 0.3155, 0.6914, 0.2982, 0.2606, 0.4472, 0.1266, 0.1311, 0.1793,
0.2747, 0.4416, 0.5603, 0.2301, 0.3357, 0.2073, 0.3647, 0.4568, 0.4276, 0.061,
0.2381, 0.0, 0.1685, 0.1351, 0.2247, 0.1351, 0.1829, 0.2576, 0.0595, 0.1829,
0.3815, 0.4555, 0.3226, 0.0, 0.0, 0.1829, 0.1562, 0.2419, 0.2647, 0.1622,
0.2469, 0.3521, 0.2232, 0.7282, 0.4133, 0.6777, 0.4898, 0.1852, 0.0993, 0.2105,
0.3318, 0.3049, 0.44, 0.6635, 0.1111, 0.3235, 0.0801, 0.1225, 0.1293, 0.3353,
0.31, 0.1429, 0.1406, 0.22, 0.2656, 0.1852, 0.4292, 0.4334, 0.3966, 0.1923,
0.1494, 0.2511, 0.1452, 0.257, 0.0971, 0.4944, 0.4118, 0.1852, 0.477, 0.2323,
0.2525, 0.7118, 0.228, 0.4406, 0.1951, 0.2391, 0.1622, 0.2395, 0.5418, 0.2823,
0.2838, 0.5704, 0.4099, 0.4596, 0.6757, 0.2151, 0.3377, 0.0987, 0.4922, 0.1699,
0.3262, 0.2, 0.0, 0.1938, 0.2063, 0.16, 0.1551, 0.2246, 0.1664, 0.2716, 0.2798,
0.1736, 0.6752, 0.5111, 0.7439, 0.7194, 0.4167, 0.1515, 0.6326, 0.8413, 0.1235,
0.3206, 0.3801, 0.3231, 0.1562, 0.3054, 0.3191, 0.0573, 0.2719, 0.0654, 0.2211,
0.4264, 0.1689, 0.2416, 0.5111, 0.4987, 0.7484, 0.1667, 0.1754, 0.4176, 0.3583,
0.0, 0.4286, 0.7597, 0.1676, 0.1931, 0.2, 0.5786, 0.1556, 0.0, 0.4009, 0.604,
0.1524, 0.2168, 0.2018, 0.722, 0.8498, 0.4323, 0.2914, 0.1471, 0.2711, 0.31,
0.2262, 0.2517, 0.0833, 0.0662, 0.2838, 0.3377, 0.2542, 0.3064, 0.1256, 0.3067,
0.1149, 0.4237, 0.3473, 0.4952, 0.3945, 0.2502, 0.2995, 0.5143, 0.1781, 0.0397,
0.098, 0.3017, 0.2101, 0.4148, 0.1376, 0.4608, 0.1563, 0.0943, 0.1282, 0.4711,
0.1524, 0.0, 0.124, 0.2561, 0.0564, 0.4121, 0.6158, 0.1603, 0.2586, 0.3975,
0.3321, 0.1111, 0.1475, 0.2857, 0.175, 0.1733, 0.3264, 0.1835, 0.2355, 0.3717,
0.499, 0.2013, 0.3695, 0.3774, 0.1572, 0.1538, 0.4406, 0.0, 0.1429, 0.0, 0.3175,
0.1327, 0.1651, 0.084, 0.2405, 0.1929, 0.1442, 0.3006, 0.654, 0.3124, 0.3003,
0.2073, 0.1036, 0.324, 0.4523, 0.1761, 0.1961, 0.4142, 0.4782, 0.6466, 0.7081,
0.3669, 0.1575, 0.2237, 0.2465, 0.3406, 0.0856, 0.2155, 0.2183, 0.5181, 0.1163,
0.0, 0.1136, 0.0, 0.1064, 0.3627, 0.3013, 0.2101, 0.2615, 0.38, 0.3568, 0.4023,
0.5558, 0.3525, 0.2369, 0.2703, 0.2652, 0.3221, 0.3623, 0.6421, 0.4373, 0.1303,
0.8528, 0.1685, 0.2404, 0.127, 0.2439, 0.0, 0.082, 0.3235, 0.194, 0.1913,
0.3931, 0.5575, 0.122, 0.1961, 0.0, 0.3712, 0.5877, 0.95, 0.7588, 0.2357,
0.0951, 0.4987, 0.1648, 0.2101, 0.2294, 0.1645, 0.1639, 0.1429, 0.375, 0.1802,
0.3126, 0.4099, 0.0933, 0.1695, 0.0936, 0.1101, 0.2162, 0.6051, 0.2812, 0.1584,
0.2645, 0.2073, 0.2304, 0.1778, 0.2303, 0.1993, 0.0586, 0.2198, 0.2, 0.2679,
0.2662, 0.2542, 0.3367, 0.237, 0.1554, 0.1087, 0.2824, 0.4828, 0.3041, 0.4074,
0.4, 0.1149, 0.4736, 0.2369, 0.1579, 0.1145, 0.5344, 0.1676, 0.1736, 0.1333,
0.1124, 0.3226, 0.3948, 0.1852, 0.2756, 0.0811, 0.611, 0.4189, 0.2294, 0.1515,
0.5563, 0.4849, 0.2752, 0.2364, 0.2837, 0.1796, 0.7134, 0.1538, 0.6149, 0.2355,
0.1948, 0.3276, 0.1734, 0.0858, 0.363, 0.3123, 0.5137, 0.2283, 0.4351], 'tranx-
annot': [0.3758, 0.8136, 0.6088, 0.1993, 0.7096, 0.7956, 0.7183, 0.3778, 0.5047,
0.2725, 0.1282, 0.4282, 0.6102, 0.4802, 0.5522, 0.1786, 0.7182, 0.6885, 0.765,
0.1692, 0.4852, 0.3784, 0.1429, 1.0, 0.8552, 1.0, 0.0688, 0.4873, 0.4808,
0.1558, 0.644, 0.1093, 0.555, 0.7426, 0.1786, 0.3012, 0.3803, 0.2922, 0.3873,
0.567, 0.0939, 0.3604, 0.5442, 0.5619, 0.5727, 0.2778, 0.5077, 0.2818, 0.8484,
0.5431, 0.8048, 0.6846, 0.5016, 0.4031, 0.1934, 0.2805, 0.2898, 0.2241, 0.0549,
0.2412, 0.284, 0.1224, 0.1883, 0.2439, 0.4384, 0.2698, 0.4046, 0.564, 0.4993,
0.356, 0.1397, 0.0652, 0.6257, 0.3354, 0.3966, 0.5627, 0.6945, 0.3717, 0.8381,
0.2078, 0.5579, 0.1389, 0.422, 0.5335, 0.808, 0.2876, 0.4649, 0.1946, 0.4908,
0.0565, 0.2075, 0.617, 0.9736, 0.583, 0.8658, 0.9759, 0.8802, 0.3035, 0.232,
0.1652, 0.3561, 0.2614, 0.5625, 0.2465, 0.1648, 0.7151, 0.2615, 0.5232, 0.1934,
0.5575, 0.416, 0.5439, 0.2433, 0.6893, 0.3316, 0.2632, 0.4547, 0.3079, 0.6013,
0.5679, 0.6013, 0.5247, 0.3234, 0.4066, 0.4096, 0.2273, 0.1238, 0.2667, 0.0,
0.4812, 0.5341, 0.3441, 0.3, 0.5556, 0.1744, 0.5048, 0.6657, 0.4761, 0.4286,
0.6195, 0.9977, 0.2074, 0.9369, 0.3297, 0.3297, 0.195, 0.3014, 0.0512, 0.5771,
0.3473, 0.2459, 0.2105, 0.1807, 0.2239, 0.6973, 0.1367, 0.6131, 0.4275, 0.8504,
0.6618, 0.3224, 0.5951, 0.3427, 0.8439, 0.3093, 0.7217, 0.625, 0.2321, 0.3108,
0.2255, 0.4543, 0.34, 0.1636, 0.4434, 0.9382, 0.4736, 0.6406, 0.507, 0.8479,
0.7531, 0.4294, 0.2657, 0.2232, 0.1523, 0.3117, 0.7947, 0.0962, 0.4404, 0.7636,
0.6511, 0.2424, 0.9139, 0.6311, 0.9269, 0.2841, 0.2583, 0.3303, 0.4589, 0.2064,
0.5203, 0.5538, 0.5538, 0.3495, 0.3561, 0.2734, 0.4032, 0.347, 0.398, 0.1,
0.6437, 0.3251, 0.5216, 0.3509, 0.6155, 0.9498, 0.625, 0.1852, 0.8032, 0.6862,
0.3751, 0.7201, 0.8829, 0.2875, 0.3226, 0.1797, 0.4932, 0.1818, 0.5213, 0.1816,
0.3948, 0.5061, 0.3992, 0.7883, 0.2027, 0.6609, 0.7523, 0.4509, 0.27, 0.3549,
0.3773, 0.5782, 0.4615, 0.909, 0.8535, 0.2784, 0.6121, 0.5, 0.4464, 0.6937,
0.4787, 0.3024, 0.2469, 0.2555, 0.4978, 0.8512, 0.7994, 0.6863, 0.3137, 0.5497,
0.686, 0.3582, 0.1887, 0.1987, 0.2163, 0.1765, 0.2616, 0.7403, 0.625, 0.3358,
0.2726, 0.3947, 0.518, 0.3226, 0.309, 0.8294, 0.6944, 0.3622, 0.6809, 0.2217,
0.7022, 0.06, 0.2031, 0.9567, 0.8363, 0.908, 0.9219, 0.3, 0.1938, 0.2481,
0.1558, 0.7002, 0.1258, 0.4795, 0.1681, 0.4595, 0.1542, 0.4791, 0.6085, 0.3219,
0.95, 0.3526, 0.3207, 0.3232, 0.3972, 0.7816, 0.5519, 0.5322, 0.4769, 0.4207,
0.9585, 0.3222, 0.2552, 0.6519, 0.1095, 0.4283, 0.232, 0.082, 0.082, 0.082,
0.8067, 0.8067, 0.8067, 0.3571, 0.0718, 0.1304, 0.4565, 0.4672, 0.3094, 0.5106,
0.654, 0.2503, 1.0, 0.2451, 0.3653, 0.7065, 0.3292, 0.5675, 0.4167, 0.4123,
0.2206, 0.8648, 0.6037, 0.3299, 0.4178, 0.4377, 0.2146, 0.6873, 0.8289, 0.2273,
0.1448, 1.0, 0.9922, 0.5437, 0.5437, 0.734, 0.734, 0.4176, 0.1449, 0.7687,
0.2929, 0.2518, 0.3568, 0.41, 0.5019, 0.4548, 0.5598, 0.3902, 0.123, 0.484,
0.2601, 0.5397, 0.5734, 0.1171, 0.5899, 0.5496, 0.5877, 0.2788, 0.1481, 0.1,
0.5091, 0.3263, 0.0833, 0.1786, 0.3981, 0.3948, 0.5943, 0.5556, 0.3814, 0.2954,
0.5024, 0.4023, 0.8376, 0.8883, 0.5597, 0.4432, 0.644, 0.0, 0.307, 0.3197,
0.4361, 0.2972, 0.25, 0.5208, 0.3276, 0.52, 0.4668, 0.2788, 0.2597, 0.1477,
0.5487, 0.3293, 0.0955, 0.0905, 0.1122, 0.2162, 0.4564, 0.6161, 0.3385, 0.1068,
0.3974, 0.6085, 0.1942, 0.83, 0.8565, 0.7683, 0.1054, 0.3683, 0.298, 0.3773,
0.3155, 0.61, 0.5203, 0.2532, 0.157, 0.3845, 0.8447, 0.3766, 0.0727, 0.2532,
0.6413, 0.3587, 0.3456, 0.2469, 0.3358, 0.5858, 0.2, 0.6155, 0.082, 0.5561,
0.2836, 0.4283, 0.6226, 0.2637, 0.2747, 0.4295, 0.7282, 0.2827, 0.5826, 0.6286,
0.7214, 0.12, 0.9985, 0.1815, 0.4356, 0.397, 0.2273, 0.0216, 0.1331, 0.3675,
0.9747, 0.2344, 0.3125], 'best-tranx': [0.4667, 0.5704, 0.4474, 0.2601, 0.7749,
0.2969, 0.9126, 1.0, 0.1289, 0.1471, 0.599, 0.7151, 0.5899, 0.5835, 0.2013,
0.7231, 0.8648, 0.3879, 0.1339, 0.0781, 0.2824, 0.4198, 0.1689, 1.0, 0.8552,
1.0, 0.0388, 0.5379, 0.5575, 0.2337, 0.4133, 0.2072, 0.3069, 0.3684, 0.4901,
0.8201, 0.3803, 0.3032, 0.3579, 0.1852, 0.2018, 0.1715, 0.3618, 0.6044, 0.3574,
0.2344, 0.8053, 0.4327, 0.8484, 0.5356, 0.8297, 0.6929, 0.2339, 0.5127, 0.1633,
0.3956, 0.3414, 0.2446, 0.2198, 0.3367, 0.4901, 0.2317, 0.6988, 0.2252, 0.5471,
0.1087, 0.2068, 0.5612, 0.4018, 0.3803, 0.2432, 0.2464, 0.4239, 0.1227, 0.6456,
0.56, 0.5411, 0.2716, 0.753, 0.4574, 0.2312, 0.1423, 0.5229, 0.8543, 0.7757,
0.3456, 0.1042, 0.2754, 0.5397, 0.0865, 0.194, 0.5403, 0.9736, 0.9132, 0.7612,
0.9759, 0.878, 0.4499, 0.5558, 0.1908, 0.341, 0.6989, 0.8294, 0.3553, 0.133,
0.24, 0.3037, 0.1942, 0.3946, 0.1923, 0.3768, 0.3673, 0.5339, 0.6796, 0.3057,
0.2564, 0.4245, 0.1765, 0.241, 0.5437, 0.241, 0.2439, 0.7533, 0.5437, 0.3875,
0.25, 0.5184, 0.5137, 0.285, 0.3947, 0.2569, 0.1302, 0.9449, 0.2174, 0.6553,
0.3628, 0.5852, 0.6347, 0.4957, 0.6427, 0.6364, 0.2691, 0.5004, 0.3841, 0.3841,
0.3002, 0.1993, 0.1316, 0.6053, 0.226, 0.3899, 0.4699, 0.1863, 0.2239, 0.7486,
0.1961, 0.9117, 0.3768, 0.6861, 0.7812, 0.3391, 0.3662, 0.318, 0.8439, 0.1498,
0.7217, 0.5686, 0.4457, 0.1923, 0.2236, 0.5393, 0.1116, 0.2703, 0.4294, 0.3695,
0.4736, 0.1923, 0.2198, 0.3679, 0.4877, 0.799, 0.1955, 0.1442, 0.2374, 0.2564,
0.7399, 0.5902, 0.5418, 0.2439, 0.5809, 0.2299, 0.83, 0.5865, 0.8552, 0.2688,
0.6907, 0.2973, 0.6819, 0.3571, 0.5891, 0.4217, 0.4217, 0.2344, 0.1014, 0.2756,
0.4618, 0.3862, 0.2302, 0.2215, 0.6437, 0.272, 0.8065, 0.6861, 0.6155, 0.9498,
0.2885, 0.5203, 0.596, 0.7601, 0.3849, 0.3902, 0.7353, 0.4968, 0.9977, 0.2435,
0.1181, 0.1422, 0.4577, 0.0796, 0.3525, 0.3876, 0.5003, 0.2407, 0.2308, 0.4271,
0.8293, 0.5489, 0.3943, 0.3911, 0.769, 0.5542, 0.1471, 0.8605, 0.888, 0.4383,
0.4402, 0.4764, 0.5757, 0.8918, 0.5375, 0.2449, 0.1007, 0.348, 0.6019, 0.4792,
0.8595, 0.5481, 0.2396, 0.1733, 0.4502, 0.4364, 0.2103, 0.2531, 0.2386, 0.2151,
0.2616, 0.7705, 0.83, 0.2958, 0.4313, 0.478, 0.5799, 0.1736, 0.2151, 0.9269,
0.999, 0.7346, 0.7817, 0.3066, 0.8684, 0.0605, 0.0797, 0.875, 0.7821, 0.7518,
0.414, 0.8372, 0.3606, 0.74, 0.1552, 0.3998, 0.1724, 0.7513, 0.3997, 0.384,
0.3488, 0.8902, 0.2604, 0.6842, 0.481, 0.2703, 0.3429, 0.6525, 0.5746, 0.9676,
0.3713, 0.5404, 0.2979, 0.2315, 0.9137, 0.3515, 0.3906, 0.3176, 0.4528, 0.4283,
0.2673, 0.2817, 0.2817, 0.2817, 0.0769, 0.0769, 0.0769, 0.3413, 0.2083, 0.4155,
0.5785, 0.5303, 0.2564, 0.3978, 0.787, 0.4455, 1.0, 0.2565, 0.4264, 0.4791,
0.3153, 0.6485, 0.999, 0.1992, 0.2778, 0.7031, 0.8737, 0.3299, 0.6707, 0.4377,
0.9136, 0.6873, 0.8888, 0.3043, 0.2236, 1.0, 0.9922, 0.9922, 0.9922, 0.8721,
0.8721, 0.5704, 0.2757, 0.7154, 0.5181, 0.3695, 0.6663, 0.4667, 0.7912, 0.6292,
0.3599, 0.2857, 0.1938, 0.5617, 0.4726, 0.4209, 0.5036, 0.149, 0.2395, 0.3628,
0.535, 0.2788, 0.7372, 0.5679, 0.5813, 0.2769, 0.2395, 0.3271, 0.4941, 0.8671,
0.6085, 0.6085, 0.3704, 0.2175, 0.7097, 0.6347, 0.8376, 0.8883, 0.5635, 0.7141,
0.5668, 0.1509, 0.2966, 0.3055, 0.9815, 0.3226, 0.1786, 0.6048, 0.7874, 0.7934,
0.3704, 0.3075, 0.4058, 0.2522, 0.5027, 0.3293, 0.3469, 0.2232, 0.599, 0.3979,
0.5456, 0.4958, 0.3824, 0.2007, 0.9999, 0.4769, 0.3221, 0.8259, 0.8236, 0.7683,
0.3895, 0.5837, 0.6585, 0.3526, 0.3407, 0.61, 0.6696, 0.4074, 0.1382, 0.2, 1.0,
0.5361, 0.2638, 0.1504, 0.8774, 0.153, 0.3755, 0.0667, 0.2506, 0.2818, 0.8775,
0.25, 0.633, 0.6308, 0.4542, 0.5471, 0.6226, 0.2637, 0.2859, 0.3289, 0.5367,
0.4467, 0.4047, 0.6897, 0.5738, 0.1587, 0.9985, 0.1429, 0.3605, 0.9088, 0.4789,
0.0439, 0.2776, 0.4745, 0.8236, 0.2916, 0.1923], 'best-tranx-rerank': [0.1408,
0.4675, 0.4474, 0.2601, 0.7749, 0.2969, 0.7129, 1.0, 0.1289, 0.1176, 0.3074,
0.7151, 0.7916, 0.5835, 0.2013, 0.7231, 0.8648, 0.3879, 0.177, 0.0771, 0.5646,
0.4198, 0.1689, 1.0, 0.8552, 1.0, 0.0388, 0.742, 0.5575, 0.2337, 0.4133, 0.2072,
0.2206, 0.3684, 0.4901, 0.9867, 0.3803, 0.194, 0.7389, 0.1852, 0.2018, 0.1715,
0.2896, 0.6044, 0.5727, 0.2344, 0.8053, 0.4327, 0.8484, 0.5356, 0.836, 0.6929,
0.2339, 0.5127, 0.1633, 0.3956, 0.3872, 0.2446, 0.2198, 0.3367, 0.5215, 0.1046,
0.6988, 0.2252, 0.5471, 0.1087, 0.2068, 0.5612, 0.4018, 0.3803, 0.2432, 0.2464,
0.2239, 0.1351, 0.6456, 0.56, 0.5097, 0.2716, 0.7559, 0.4676, 0.2312, 0.1772,
0.5229, 0.8543, 0.7757, 0.3456, 0.1042, 0.2754, 0.5397, 0.0865, 0.192, 0.5403,
0.9736, 0.9132, 0.7612, 0.9759, 0.878, 0.4499, 0.5558, 0.3891, 0.341, 0.6989,
0.8294, 0.3553, 0.3859, 0.8654, 0.3037, 0.205, 0.2717, 0.4808, 0.3768, 0.3673,
0.166, 0.6796, 0.3057, 0.2941, 0.4245, 0.1765, 0.241, 0.5437, 0.241, 0.2439,
0.7533, 0.5437, 0.3242, 0.25, 0.5184, 0.5137, 0.285, 0.3947, 0.2569, 0.1562,
0.9449, 0.2174, 0.6553, 0.3628, 0.5852, 0.6347, 0.4627, 0.6427, 0.6364, 0.2691,
0.7635, 0.531, 0.531, 0.3002, 0.6181, 0.1171, 0.6053, 0.226, 0.3899, 0.4699,
0.5845, 0.2239, 0.3758, 0.1961, 0.9117, 0.3768, 0.6861, 0.7308, 0.5238, 0.3662,
0.318, 0.7876, 0.6039, 0.7217, 0.5686, 0.7629, 0.1923, 0.2236, 0.5393, 0.1116,
0.2703, 0.4294, 0.8045, 0.4736, 0.2703, 0.2198, 0.3679, 0.2976, 0.799, 0.1955,
0.1442, 0.2184, 0.1852, 0.7399, 0.3942, 0.5418, 0.3252, 0.7717, 0.2976, 0.83,
0.5865, 0.8552, 0.5437, 0.6907, 0.4424, 0.6819, 0.3571, 0.5924, 0.4217, 0.4217,
0.2344, 0.1014, 0.2362, 0.5222, 0.599, 0.2451, 0.2215, 0.6437, 0.272, 0.8065,
0.6861, 0.6155, 0.9498, 0.3947, 0.5203, 0.596, 0.7601, 0.3849, 0.2982, 0.7353,
0.4968, 0.9977, 0.2435, 0.1181, 0.1422, 0.416, 0.2662, 0.3525, 0.8195, 0.5003,
0.7782, 0.2459, 0.4025, 0.8198, 0.5489, 0.2898, 0.48, 0.769, 0.7986, 0.4628,
0.8605, 0.888, 0.3847, 0.4402, 0.4764, 0.5757, 0.8918, 0.5118, 0.2626, 0.1007,
0.3204, 0.6019, 0.9922, 0.893, 0.5481, 0.1325, 0.237, 0.4915, 0.4364, 0.2103,
0.2531, 0.2386, 0.2151, 0.2616, 0.1838, 0.83, 0.2958, 0.4697, 0.478, 0.5123,
0.1736, 0.286, 0.9269, 0.999, 0.6593, 0.7094, 0.3859, 0.6667, 0.0605, 0.0605,
0.726, 0.594, 0.7518, 0.6226, 0.6862, 0.5445, 0.74, 0.1552, 0.3998, 0.1724,
0.6242, 0.3997, 0.5264, 0.3488, 0.8902, 0.2688, 0.3547, 0.25, 0.2703, 0.8529,
0.6525, 0.5746, 0.9676, 0.4544, 0.5404, 0.8625, 0.2655, 0.9137, 0.3515, 0.3906,
0.6013, 0.1786, 0.4283, 0.2977, 0.7562, 0.7562, 0.2817, 0.0769, 0.0769, 0.0769,
0.3876, 0.2315, 0.4155, 0.5785, 0.5303, 0.2564, 0.3978, 0.787, 0.4455, 1.0,
0.2244, 0.4264, 0.4791, 0.3153, 0.7168, 0.999, 0.1992, 0.2778, 0.7031, 0.8737,
0.3299, 0.5391, 0.4377, 0.9136, 0.6873, 0.8888, 0.3043, 0.1689, 1.0, 0.9922,
0.9922, 0.9922, 0.9922, 0.9922, 0.5704, 0.2757, 0.752, 0.5181, 0.3695, 0.6663,
0.6862, 0.7912, 0.6292, 0.6092, 0.2857, 0.1938, 0.5625, 0.4726, 0.5361, 0.1508,
0.149, 0.2395, 0.3628, 0.5204, 0.2788, 0.8255, 0.7361, 0.5813, 0.2434, 0.2395,
0.3271, 0.3904, 0.8671, 0.6085, 0.6085, 0.3704, 0.0893, 0.7097, 0.6347, 0.8376,
0.8883, 0.5635, 0.7141, 0.5668, 0.1509, 0.3017, 0.6182, 0.9997, 0.3226, 0.1786,
0.8137, 0.7874, 0.7934, 0.3704, 0.3075, 0.4625, 0.2522, 0.5027, 0.3293, 0.3469,
0.3609, 0.6969, 0.3979, 0.6511, 0.4958, 0.6, 0.2007, 0.9999, 0.8721, 0.3221,
0.8259, 0.8737, 0.7683, 0.1718, 0.5837, 0.2961, 0.3595, 0.3407, 0.61, 0.6696,
0.3125, 0.3222, 0.2, 1.0, 0.5361, 0.2254, 0.1504, 0.8774, 0.4531, 0.4488,
0.0667, 0.2506, 0.6601, 0.8775, 0.25, 0.633, 0.6308, 0.4542, 0.5471, 0.6226,
0.2637, 0.2859, 0.3289, 0.5367, 0.3755, 0.4216, 0.6897, 0.5738, 0.1587, 0.4167,
0.1429, 0.3605, 0.9088, 0.4789, 0.0439, 0.3227, 0.4745, 0.8236, 0.3108,
0.3465]\}, 'ruby': \{'baseline': [0.42307692307692313, 0.5833333333333333,
0.4722222222222222, 0.31818181818181823, 0.38888888888888884, 0.48, 0.5,
0.8095238095238095, 0.18518518518518523, 0.8125, 0.46153846153846156, 0.0, 0.75,
0.10526315789473684, 0.2962962962962963, 0.45833333333333337, 0.36, 0.53125,
0.65, 0.55, 0.72, 0.5263157894736843, 0.6470588235294117, 0.4666666666666667,
0.30000000000000004, 0.9090909090909091, 0.05294117647058827,
0.6428571428571428, 0.6, 0.03703703703703709, 0.5652173913043479,
0.5714285714285714, 0.25, 0.5789473684210527, 0.6153846153846154,
0.6470588235294117, 0.5384615384615384, 0.25806451612903225, 0.76,
0.4642857142857143, 0.4444444444444444, 0.3695652173913043, 0.6451612903225806,
0.4, 0.6111111111111112, 0.19999999999999996, 0.1578947368421053, 0.625, 0.55,
0.3571428571428571, 0.64, 0.3928571428571429, 0.6060606060606061, 0.5,
0.15909090909090906, 0.16666666666666663, 0.28, 0.5555555555555556,
0.15384615384615385, 0.30434782608695654, 0.1428571428571429,
0.46153846153846156, 0.1428571428571429, 0.2727272727272727, 0.8,
0.6086956521739131, 0.5, 0.11538461538461542, 0.43999999999999995,
0.42307692307692313, 0.28, 0.631578947368421, 0.2622950819672131,
0.33333333333333337, 0.3870967741935484, 0.41463414634146345,
0.42105263157894735, 0.88, 0.05084745762711862, 0.6956521739130435,
0.23404255319148937, 0.4117647058823529, 0.375, 0.4, 0.47058823529411764,
0.41463414634146345, 0.13636363636363635, 0.46341463414634143, 0.40625,
0.2558139534883721, 0.375, 0.48, 0.45833333333333337, 0.4375,
0.5555555555555556, 0.30434782608695654, 0.8181818181818181,
0.32499999999999996, 0.6428571428571428, 0.6428571428571428, 0.1578947368421053,
0.23529411764705888, 0.6774193548387097, 0.23529411764705888,
0.43999999999999995, 0.35, 0.12, 0.15625, 0.2857142857142857,
0.6666666666666667, 0.75, 0.7272727272727273, 0.7058823529411764,
0.6086956521739131, 0.48, 0.6, 0.4, 0.4482758620689655, 0.36363636363636365,
0.6875, 0.38888888888888884, 0.4642857142857143, 0.38095238095238093,
0.36111111111111116, 0.38095238095238093, 0.75, 0.25531914893617025,
0.05714285714285716, 0.38235294117647056, 0.2962962962962963,
0.4651162790697675, 0.30952380952380953, 0.0, 0.0, 0.4347826086956522, 0.5,
0.6153846153846154, 0.3783783783783784, 0.1578947368421053, 0.36111111111111116,
0.5833333333333333, 0.6956521739130435, 0.8571428571428572, 0.6,
0.6842105263157895, 0.3870967741935484, 0.23684210526315785, 0.1875,
0.5238095238095238, 0.3666666666666667, 0.5, 0.368421052631579,
0.782608695652174, 0.2727272727272727, 0.29166666666666663, 0.1470588235294118,
0.19047619047619047, 0.125, 0.6666666666666667, 0.14754098360655743,
0.3877551020408163, 0.16000000000000003, 0.28, 0.3589743589743589,
0.26190476190476186, 0.6086956521739131, 0.6086956521739131,
0.15384615384615385, 0.3090909090909091, 0.44999999999999996,
0.6956521739130435, 0.3793103448275862, 0.375, 0.5, 0.6666666666666667,
0.7619047619047619, 0.4782608695652174, 0.7173913043478262, 0.43999999999999995,
0.43999999999999995, 0.5641025641025641, 0.34615384615384615,
0.47058823529411764, 0.29032258064516125, 0.631578947368421, 0.4864864864864865,
0.3571428571428571, 0.7045454545454546, 0.31034482758620685, 0.4838709677419355,
0.4117647058823529, 0.5833333333333333, 0.6666666666666667, 0.9090909090909091,
0.19047619047619047, 0.3448275862068966, 0.2857142857142857, 0.4285714285714286,
0.6666666666666667, 0.5909090909090908, 0.25, 0.44999999999999996,
0.23529411764705888, 0.5333333333333333, 0.5925925925925926, 0.2666666666666667,
0.37142857142857144, 0.3653846153846154, 0.5238095238095238, 0.4482758620689655,
0.2954545454545454, 0.31818181818181823, 0.25, 0.3513513513513513,
0.7692307692307692, 0.4117647058823529, 0.28, 0.8571428571428572,
0.8571428571428572, 0.21052631578947367, 0.1875, 0.6, 0.3793103448275862,
0.09999999999999998, 0.1875, 0.25, 0.0, 0.2962962962962963, 0.3448275862068966,
0.40816326530612246, 0.5909090909090908, 0.43999999999999995,
0.5238095238095238, 0.8571428571428572, 0.7241379310344828, 0.4242424242424242,
0.46153846153846156, 0.16326530612244894, 0.34615384615384615,
0.19999999999999996, 0.20512820512820518, 0.2222222222222222,
0.7924528301886793, 0.40909090909090906, 0.3783783783783784, 0.4772727272727273,
0.5172413793103448, 0.21739130434782605, 0.0, 0.29166666666666663,
0.6799999999999999, 0.4, 0.20588235294117652, 0.31034482758620685,
0.40909090909090906, 0.6470588235294117, 0.25, 0.15625, 0.2857142857142857,
0.5384615384615384, 0.41666666666666663, 0.2894736842105263, 0.1333333333333333,
0.1875, 0.40909090909090906, 0.29268292682926833, 0.4054054054054054,
0.7333333333333334, 0.25, 0.26086956521739135, 0.4736842105263158, 0.25,
0.1333333333333333, 0.6428571428571428, 0.5714285714285714, 0.6875,
0.23684210526315785, 0.20588235294117652, 0.31707317073170727,
0.18333333333333335, 0.07407407407407407, 0.4, 0.18181818181818177,
0.24193548387096775, 0.6842105263157895, 0.052631578947368474,
0.25806451612903225, 0.5, 0.36363636363636365, 0.4347826086956522,
0.3214285714285714, 0.4482758620689655, 0.0, 0.46153846153846156,
0.36363636363636365, 0.020000000000000018, 0.6206896551724138,
0.6521739130434783, 0.4545454545454546, 0.5277777777777778, 0.4285714285714286,
0.9, 0.1724137931034483, 0.06451612903225812, 0.8333333333333334,
0.7058823529411764, 0.2592592592592593, 0.6190476190476191, 0.10526315789473684,
0.15384615384615385, 0.31818181818181823, 0.3076923076923077,
0.5294117647058824, 0.6666666666666667, 0.6037735849056604, 0.0888888888888889,
0.5882352941176471, 0.75, 0.5333333333333333, 0.1785714285714286,
0.368421052631579, 0.7058823529411764, 0.37142857142857144, 0.35416666666666663,
0.16666666666666663, 0.06060606060606055, 0.21621621621621623,
0.43999999999999995, 0.4545454545454546, 0.7441860465116279, 0.64,
0.08823529411764708, 0.5238095238095238, 0.19999999999999996,
0.43999999999999995, 0.17391304347826086, 0.5416666666666667,
0.4117647058823529, 0.6, 0.6111111111111112, 0.5862068965517242,
0.8846153846153846, 0.625, 0.21052631578947367, 0.2790697674418605, 0.65,
0.18604651162790697, 0.7222222222222222, 0.4545454545454546, 0.2941176470588235,
0.8571428571428572, 0.4117647058823529, 0.4117647058823529, 0.0, 0.0, 0.0,
0.6923076923076923, 0.3076923076923077, 0.5238095238095238, 0.1578947368421053,
0.4838709677419355, 0.6428571428571428, 0.5769230769230769, 0.4666666666666667,
0.5925925925925926, 0.55, 0.17391304347826086, 0.16666666666666663,
0.5882352941176471, 0.55, 0.5, 0.5454545454545454, 0.45833333333333337, 0.75,
0.5555555555555556, 0.5714285714285714, 0.8125, 0.375, 0.46153846153846156, 0.5,
0.5, 0.4347826086956522, 0.43999999999999995, 0.31999999999999995,
0.7647058823529411, 0.5294117647058824, 0.125, 0.44999999999999996,
0.4482758620689655, 0.6363636363636364, 0.736842105263158, 0.8928571428571429,
0.25, 0.3793103448275862, 0.5294117647058824, 0.4736842105263158,
0.3793103448275862, 0.26315789473684215, 0.4054054054054054, 0.5,
0.6206896551724138, 0.5, 0.25, 0.29166666666666663, 0.6875, 0.26315789473684215,
0.4651162790697675, 0.3846153846153846, 0.22499999999999998,
0.19999999999999996, 0.65, 0.41463414634146345, 0.17391304347826086,
0.3448275862068966, 0.13636363636363635, 0.2727272727272727,
0.18518518518518523, 0.64, 0.032258064516129004, 0.01342281879194629,
0.5357142857142857, 0.19999999999999996, 0.6, 0.08333333333333337,
0.5714285714285714, 0.5714285714285714, 0.3191489361702128, 0.631578947368421,
0.625, 0.4864864864864865, 0.31818181818181823, 0.2564102564102564,
0.3513513513513513, 0.34782608695652173, 0.23076923076923073,
0.2530120481927711, 0.4347826086956522, 0.2564102564102564, 0.5,
0.19999999999999996, 0.4285714285714286, 0.6190476190476191, 0.3125, 0.4,
0.4285714285714286, 0.6666666666666667, 0.11111111111111116,
0.11111111111111116, 0.10526315789473684, 0.9047619047619048,
0.2142857142857143, 0.5625, 0.16129032258064513, 0.4642857142857143, 0.875,
0.3846153846153846, 0.8095238095238095, 0.9, 0.21739130434782605,
0.5882352941176471, 0.18181818181818177, 0.6666666666666667, 0.3076923076923077,
0.33333333333333337, 0.5714285714285714, 0.4375, 0.3870967741935484,
0.7727272727272727, 0.3157894736842105, 0.36363636363636365,
0.34693877551020413, 0.41666666666666663], 'tranx-annot': [0.375,
0.6363636363636364, 0.5625, 0.3513513513513513, 0.4285714285714286,
0.8666666666666667, 0.55, 0.6086956521739131, 0.2692307692307693,
0.5217391304347826, 0.19999999999999996, 0.13636363636363635,
0.40909090909090906, 0.5806451612903225, 0.6551724137931034, 0.4347826086956522,
0.7222222222222222, 0.6756756756756757, 0.9130434782608696, 0.21621621621621623,
0.6451612903225806, 0.6190476190476191, 0.6470588235294117, 0.8888888888888888,
0.8888888888888888, 1.0, 0.0, 0.23333333333333328, 0.7, 0.05660377358490565,
0.5652173913043479, 0.25806451612903225, 0.7105263157894737,
0.37037037037037035, 0.02941176470588236, 0.3913043478260869, 0.5,
0.36734693877551017, 0.34883720930232553, 0.78125, 0.21212121212121215,
0.6190476190476191, 0.5925925925925926, 0.6551724137931034, 0.6666666666666667,
0.31999999999999995, 0.2272727272727273, 0.4193548387096774, 0.736842105263158,
0.24528301886792447, 0.5217391304347826, 0.3846153846153846, 0.6060606060606061,
0.4878048780487805, 0.3529411764705882, 0.4736842105263158, 0.5593220338983051,
0.12, 0.47619047619047616, 0.537037037037037, 0.2432432432432432,
0.32499999999999996, 0.5909090909090908, 0.40909090909090906, 0.28125,
0.21276595744680848, 0.5416666666666667, 0.3846153846153846, 0.4411764705882353,
0.34782608695652173, 0.3214285714285714, 0.7333333333333334, 0.5319148936170213,
0.475, 0.5, 0.7560975609756098, 0.4821428571428571, 0.28205128205128205,
0.5454545454545454, 0.30000000000000004, 0.64, 0.1923076923076923,
0.7083333333333333, 0.4444444444444444, 0.7333333333333334, 0.4545454545454546,
0.5833333333333333, 0.3913043478260869, 0.6190476190476191, 0.3207547169811321,
0.5769230769230769, 0.33333333333333337, 0.8333333333333334, 0.2222222222222222,
0.8571428571428572, 0.9047619047619048, 0.7037037037037037, 0.32499999999999996,
0.38888888888888884, 0.41666666666666663, 0.6, 0.4871794871794872,
0.6666666666666667, 0.25, 0.4285714285714286, 0.5517241379310345, 0.28,
0.8235294117647058, 0.4516129032258065, 0.8636363636363636, 0.7,
0.7894736842105263, 0.5, 0.46875, 0.19999999999999996, 0.38235294117647056,
0.4871794871794872, 0.3846153846153846, 0.36, 0.525, 0.36, 0.5416666666666667,
0.4137931034482759, 0.4222222222222223, 0.3846153846153846, 0.3913043478260869,
0.26, 0.5294117647058824, 0.0, 0.6799999999999999, 0.5128205128205128, 0.25,
0.34782608695652173, 0.5, 0.4444444444444444, 0.2857142857142857,
0.6799999999999999, 0.2857142857142857, 0.1428571428571429, 0.42105263157894735,
1.0, 0.5714285714285714, 0.8571428571428572, 0.1724137931034483,
0.1724137931034483, 0.46153846153846156, 0.5625, 0.030303030303030276,
0.3448275862068966, 0.23809523809523814, 0.33333333333333337,
0.5238095238095238, 0.2647058823529411, 0.45945945945945943, 0.7868852459016393,
0.21052631578947367, 0.8108108108108107, 0.39473684210526316,
0.7333333333333334, 0.5897435897435898, 0.4117647058823529, 0.6304347826086957,
0.46153846153846156, 0.7543859649122807, 0.45833333333333337,
0.6666666666666667, 0.64, 0.359375, 0.30612244897959184, 0.17948717948717952,
0.6071428571428572, 0.5238095238095238, 0.5471698113207547, 0.41666666666666663,
0.5517241379310345, 0.631578947368421, 0.7307692307692308, 0.6458333333333333,
0.7241379310344828, 0.7352941176470589, 0.1578947368421053, 0.3220338983050848,
0.5, 0.4, 0.5652173913043479, 0.8333333333333334, 0.21739130434782605,
0.6181818181818182, 0.6538461538461539, 0.8125, 0.3448275862068966,
0.9545454545454546, 0.6666666666666667, 0.9090909090909091, 0.47058823529411764,
0.16666666666666663, 0.4375, 0.5555555555555556, 0.4285714285714286,
0.29032258064516125, 0.5925925925925926, 0.5925925925925926, 0.5714285714285714,
0.3571428571428571, 0.7, 0.37142857142857144, 0.6774193548387097,
0.5434782608695652, 0.5882352941176471, 0.4642857142857143, 0.33999999999999997,
0.23684210526315785, 0.16666666666666663, 0.33333333333333337,
0.8461538461538461, 0.9, 0.5517241379310345, 0.75, 0.8333333333333334, 0.5,
0.5294117647058824, 0.6818181818181819, 0.22580645161290325, 0.6818181818181819,
0.3125, 0.8823529411764706, 0.32258064516129037, 0.6097560975609756,
0.33333333333333337, 0.5319148936170213, 0.6538461538461539, 0.5454545454545454,
0.6111111111111112, 0.10344827586206895, 0.5, 0.36363636363636365, 0.5,
0.2857142857142857, 0.7647058823529411, 0.46875, 0.3939393939393939,
0.4347826086956522, 0.92, 0.8888888888888888, 0.2978723404255319, 0.4,
0.6666666666666667, 0.37142857142857144, 0.6756756756756757, 0.85,
0.5238095238095238, 0.4358974358974359, 0.8095238095238095, 0.4838709677419355,
0.8285714285714285, 0.8235294117647058, 0.7540983606557377, 0.38961038961038963,
0.5384615384615384, 0.6153846153846154, 0.30000000000000004, 0.4666666666666667,
0.2692307692307693, 0.3913043478260869, 0.5789473684210527, 0.22857142857142854,
0.6, 0.875, 0.5238095238095238, 0.19047619047619047, 0.641025641025641,
0.5777777777777777, 0.4, 0.625, 0.8888888888888888, 0.7894736842105263,
0.31481481481481477, 0.6065573770491803, 0.43333333333333335,
0.6031746031746033, 0.09999999999999998, 0.25, 0.9444444444444444,
0.8723404255319149, 0.8666666666666667, 0.7727272727272727, 0.4736842105263158,
0.4482758620689655, 0.44999999999999996, 0.2666666666666667, 0.6153846153846154,
0.4444444444444444, 0.5862068965517242, 0.3928571428571429, 0.3902439024390244,
0.5238095238095238, 0.4651162790697675, 0.33333333333333337, 0.5882352941176471,
0.84375, 0.42105263157894735, 0.8571428571428572, 0.8571428571428572,
0.5416666666666667, 0.52, 0.8888888888888888, 0.4137931034482759,
0.7619047619047619, 0.16666666666666663, 0.8285714285714285, 0.5,
0.43333333333333335, 0.782608695652174, 0.43999999999999995,
0.34782608695652173, 0.32727272727272727, 0.0, 0.0, 0.0, 0.9444444444444444,
0.9444444444444444, 0.9444444444444444, 0.4285714285714286, 0.34090909090909094,
0.4, 0.48484848484848486, 0.4897959183673469, 0.46153846153846156,
0.5555555555555556, 0.7441860465116279, 0.23684210526315785, 0.95,
0.15384615384615385, 0.5, 0.5769230769230769, 0.38636363636363635,
0.32258064516129037, 0.3076923076923077, 0.46341463414634143,
0.2142857142857143, 0.9545454545454546, 0.59375, 0.5, 0.09302325581395354,
0.5111111111111111, 0.33333333333333337, 0.6415094339622642,
0.12903225806451613, 0.5185185185185186, 0.12765957446808507, 0.95, 1.0,
0.47619047619047616, 0.47619047619047616, 0.7647058823529411,
0.7647058823529411, 0.4375, 0.22857142857142854, 0.875, 0.4054054054054054,
0.5357142857142857, 0.6666666666666667, 0.7142857142857143, 0.5757575757575757,
0.6060606060606061, 0.5238095238095238, 0.5652173913043479, 0.30000000000000004,
0.5789473684210527, 0.11428571428571432, 0.5813953488372092, 0.5416666666666667,
0.42307692307692313, 0.525, 0.6842105263157895, 0.40740740740740744, 0.9375,
0.15909090909090906, 0.21052631578947367, 0.7647058823529411,
0.19999999999999996, 0.3913043478260869, 0.32558139534883723, 0.48,
0.5151515151515151, 0.7058823529411764, 0.5, 0.7058823529411764,
0.4242424242424242, 0.6818181818181819, 0.5625, 0.9285714285714286,
0.8333333333333334, 0.31999999999999995, 0.29032258064516125,
0.8666666666666667, 0.0, 0.4242424242424242, 0.1333333333333333,
0.0714285714285714, 0.5806451612903225, 0.4375, 0.7727272727272727,
0.42307692307692313, 0.7777777777777778, 0.4545454545454546, 0.4358974358974359,
0.475, 0.4, 0.375, 0.625, 0.21621621621621623, 0.13636363636363635,
0.30612244897959184, 0.38235294117647056, 0.4285714285714286,
0.46808510638297873, 0.25, 0.25806451612903225, 0.1333333333333333,
0.5714285714285714, 0.42307692307692313, 0.4347826086956522, 0.7777777777777778,
0.375, 0.31999999999999995, 0.4571428571428572, 0.6190476190476191,
0.6666666666666667, 0.6, 0.7567567567567568, 0.5, 0.32432432432432434,
0.26086956521739135, 0.2894736842105263, 0.7333333333333334, 0.4666666666666667,
0.11428571428571432, 0.18918918918918914, 0.5555555555555556,
0.4545454545454546, 0.65, 0.4285714285714286, 0.5, 0.5135135135135135,
0.6190476190476191, 0.5, 0.23809523809523814, 0.25, 0.3157894736842105,
0.6923076923076923, 0.47058823529411764, 0.2666666666666667, 0.3076923076923077,
0.6842105263157895, 0.6363636363636364, 0.11904761904761907, 0.5555555555555556,
0.8823529411764706, 0.7291666666666667, 0.11764705882352944, 1.0,
0.38888888888888884, 0.41666666666666663, 0.6129032258064516,
0.5945945945945945, 0.19999999999999996, 0.33333333333333337,
0.4814814814814815, 0.7777777777777778, 0.4893617021276596, 0.3214285714285714],
'best-tranx': [0.41666666666666663, 0.2941176470588235, 0.125,
0.2647058823529411, 0.7692307692307692, 0.2564102564102564, 0.5121951219512195,
1.0, 0.46153846153846156, 0.5263157894736843, 0.65625, 0.33333333333333337,
0.5789473684210527, 0.7419354838709677, 0.5, 0.40740740740740744, 0.9375,
0.6428571428571428, 0.5652173913043479, 0.4, 0.5416666666666667,
0.4814814814814815, 0.5384615384615384, 0.8888888888888888, 0.8888888888888888,
1.0, 0.0, 0.43333333333333335, 0.8636363636363636, 0.019230769230769273,
0.7272727272727273, 0.25806451612903225, 0.65, 0.7777777777777778,
0.6428571428571428, 0.7, 0.5, 0.30434782608695654, 0.2692307692307693,
0.3793103448275862, 0.36111111111111116, 0.18181818181818177,
0.28205128205128205, 0.5333333333333333, 0.2666666666666667, 0.1923076923076923,
0.44999999999999996, 0.6470588235294117, 0.736842105263158, 0.43181818181818177,
0.4137931034482759, 0.43999999999999995, 0.43333333333333335,
0.7297297297297297, 0.43999999999999995, 0.6818181818181819, 0.5535714285714286,
0.5094339622641509, 0.6, 0.6382978723404256, 0.48888888888888893,
0.43181818181818177, 0.64, 0.5161290322580645, 0.6818181818181819,
0.45833333333333337, 0.5, 0.46153846153846156, 0.40909090909090906,
0.5333333333333333, 0.4642857142857143, 0.631578947368421, 0.4375,
0.28301886792452835, 0.44999999999999996, 0.375, 0.4893617021276596,
0.7083333333333333, 0.6, 0.38095238095238093, 0.5102040816326531,
0.4411764705882353, 0.40909090909090906, 0.625, 0.625, 0.4871794871794872,
0.2571428571428571, 0.4651162790697675, 0.3783783783783784, 0.38636363636363635,
0.46875, 0.7307692307692308, 0.8333333333333334, 0.4736842105263158,
0.7741935483870968, 0.9047619047619048, 0.6666666666666667, 0.5,
0.6785714285714286, 0.36111111111111116, 0.5652173913043479, 0.7333333333333334,
0.8125, 0.7777777777777778, 0.23529411764705888, 0.4285714285714286,
0.6666666666666667, 0.303030303030303, 0.43243243243243246, 0.5789473684210527,
0.3125, 0.4, 0.5869565217391304, 0.5, 0.5102040816326531, 0.4137931034482759,
0.6451612903225806, 0.36, 0.18181818181818177, 0.6585365853658536,
0.18181818181818177, 0.47619047619047616, 0.7551020408163265,
0.42307692307692313, 0.41666666666666663, 0.7058823529411764,
0.6166666666666667, 0.5294117647058824, 0.24, 0.4054054054054054,
0.43243243243243246, 0.3846153846153846, 0.75, 0.47619047619047616, 0.85, 0.75,
0.3913043478260869, 0.44897959183673475, 0.4, 0.525, 0.6, 0.6666666666666667,
0.04878048780487809, 0.0, 0.0, 0.5454545454545454, 0.2857142857142857,
0.36585365853658536, 0.6521739130434783, 0.40625, 0.5416666666666667,
0.3846153846153846, 0.3448275862068966, 0.11764705882352944, 0.7777777777777778,
0.3653846153846154, 0.9705882352941176, 0.37142857142857144, 0.2592592592592593,
0.6190476190476191, 0.525, 0.28125, 0.16000000000000003, 0.7457627118644068,
0.1785714285714286, 0.6666666666666667, 0.6666666666666667, 0.4772727272727273,
0.14, 0.20512820512820518, 0.9545454545454546, 0.47619047619047616,
0.4385964912280702, 0.11363636363636365, 0.4516129032258065, 0.631578947368421,
0.4545454545454546, 0.5365853658536586, 0.47619047619047616,
0.44999999999999996, 0.39583333333333337, 0.23529411764705888,
0.30434782608695654, 0.4193548387096774, 0.16279069767441856,
0.8918918918918919, 0.6071428571428572, 0.7045454545454546, 0.33333333333333337,
0.575, 0.1428571428571429, 0.9090909090909091, 0.6296296296296297,
0.8636363636363636, 0.34375, 0.6296296296296297, 0.2857142857142857,
0.6976744186046512, 0.9, 0.5384615384615384, 0.34285714285714286,
0.34285714285714286, 0.3055555555555556, 0.36, 0.6071428571428572,
0.4117647058823529, 0.5555555555555556, 0.33333333333333337, 0.6842105263157895,
0.4642857142857143, 0.6037735849056604, 0.36363636363636365, 0.5789473684210527,
0.33333333333333337, 0.8461538461538461, 0.030303030303030276,
0.5833333333333333, 0.8333333333333334, 0.5925925925925926, 0.53125,
0.47058823529411764, 0.5294117647058824, 0.3548387096774194, 1.0,
0.5172413793103448, 0.5483870967741935, 0.6666666666666667, 0.8108108108108107,
0.2692307692307693, 0.47916666666666663, 0.4666666666666667, 0.6363636363636364,
0.5909090909090908, 0.23809523809523814, 0.22448979591836737,
0.46153846153846156, 0.4375, 0.5757575757575757, 0.046511627906976716,
0.4411764705882353, 0.6, 0.36, 0.8269230769230769, 0.8888888888888888,
0.276595744680851, 0.47058823529411764, 0.5925925925925926, 0.34782608695652173,
0.96875, 0.9, 0.3913043478260869, 0.23076923076923073, 0.38235294117647056,
0.46875, 0.25, 0.6190476190476191, 0.6666666666666667, 0.15625,
0.23809523809523814, 0.4375, 0.5909090909090908, 0.41666666666666663,
0.26086956521739135, 0.46153846153846156, 0.4482758620689655,
0.22857142857142854, 0.6, 0.9375, 0.4782608695652174, 0.5238095238095238,
0.5476190476190477, 0.6666666666666667, 0.5, 0.21052631578947367,
0.9444444444444444, 1.0, 0.6190476190476191, 0.5769230769230769,
0.26086956521739135, 0.5454545454545454, 0.10256410256410253,
0.14814814814814814, 0.5466666666666666, 0.48863636363636365,
0.2549019607843137, 0.5652173913043479, 0.9047619047619048, 0.25,
0.7916666666666666, 0.7272727272727273, 0.38095238095238093, 0.4242424242424242,
0.7222222222222222, 0.7407407407407407, 0.2682926829268293, 0.9,
0.8108108108108107, 0.4666666666666667, 0.6, 0.5428571428571429,
0.2592592592592593, 0.21739130434782605, 0.95, 0.37142857142857144,
0.8888888888888888, 0.2962962962962963, 0.34615384615384615, 0.5,
0.16666666666666663, 0.5238095238095238, 0.40384615384615385,
0.3666666666666667, 0.736842105263158, 0.4814814814814815, 0.34782608695652173,
0.4, 0.3666666666666667, 0.375, 0.3666666666666667, 0.33333333333333337,
0.33333333333333337, 0.33333333333333337, 0.4444444444444444,
0.3846153846153846, 0.19999999999999996, 0.6666666666666667, 0.5217391304347826,
0.2702702702702703, 0.65, 0.8478260869565217, 0.782608695652174, 0.95,
0.7222222222222222, 0.5555555555555556, 0.43333333333333335, 0.3913043478260869,
0.53125, 1.0, 0.3589743589743589, 0.33333333333333337, 0.9090909090909091,
0.6875, 0.5, 0.24, 0.5111111111111111, 0.8787878787878788, 0.6415094339622642,
0.65, 0.25, 0.2222222222222222, 0.95, 1.0, 1.0, 1.0, 0.7647058823529411,
0.7647058823529411, 0.47058823529411764, 0.37037037037037035, 0.631578947368421,
0.6595744680851063, 0.625, 0.7333333333333334, 0.3421052631578947,
0.8709677419354839, 0.8387096774193549, 0.5238095238095238, 0.29166666666666663,
0.3157894736842105, 0.21739130434782605, 0.4, 0.2857142857142857,
0.6190476190476191, 0.5, 0.05555555555555558, 0.6470588235294117,
0.3448275862068966, 0.9375, 0.5833333333333333, 0.5333333333333333,
0.7647058823529411, 0.2666666666666667, 0.64, 0.5384615384615384,
0.6599999999999999, 0.8108108108108107, 0.75, 0.75, 0.7894736842105263,
0.5161290322580645, 0.9545454545454546, 0.736842105263158, 0.9285714285714286,
0.8333333333333334, 0.3076923076923077, 0.64, 0.13888888888888884,
0.27586206896551724, 0.36111111111111116, 0.31818181818181823,
0.9333333333333333, 0.4864864864864865, 0.34782608695652173,
0.33333333333333337, 0.6428571428571428, 0.8888888888888888,
0.34090909090909094, 0.5365853658536586, 0.34375, 0.5238095238095238, 0.6,
0.625, 0.3902439024390244, 0.39622641509433965, 0.5757575757575757,
0.4242424242424242, 0.5428571428571429, 0.43243243243243246, 0.5483870967741935,
0.368421052631579, 1.0, 0.75, 0.5, 0.7058823529411764, 0.8235294117647058,
0.375, 0.6176470588235294, 0.6976744186046512, 0.85, 0.5, 0.4,
0.7567567567567568, 0.41463414634146345, 0.3783783783783784,
0.26086956521739135, 0.30000000000000004, 1.0, 0.5217391304347826,
0.5116279069767442, 0.65, 0.94, 0.29166666666666663, 0.09090909090909094, 0.125,
0.5384615384615384, 0.36363636363636365, 0.8571428571428572, 0.5789473684210527,
0.8666666666666667, 0.4736842105263158, 0.8, 0.7241379310344828,
0.47058823529411764, 0.2666666666666667, 0.4, 0.6428571428571428, 0.5, 0.3125,
0.2093023255813954, 0.5, 0.6842105263157895, 0.2222222222222222, 1.0,
0.3921568627450981, 0.375, 0.8333333333333334, 0.6129032258064516,
0.15384615384615385, 0.9, 0.43333333333333335, 0.5882352941176471,
0.20833333333333337, 0.21739130434782605], 'best-tranx-rerank':
[0.41666666666666663, 0.4117647058823529, 0.125, 0.2647058823529411,
0.7692307692307692, 0.2564102564102564, 0.5, 1.0, 0.46153846153846156,
0.5263157894736843, 0.31999999999999995, 0.33333333333333337, 0.625,
0.7419354838709677, 0.5, 0.40740740740740744, 0.9375, 0.6428571428571428, 0.6,
0.29032258064516125, 0.6206896551724138, 0.4814814814814815, 0.5384615384615384,
0.8888888888888888, 0.8888888888888888, 1.0, 0.0, 0.5333333333333333,
0.8636363636363636, 0.019230769230769273, 0.7272727272727273,
0.25806451612903225, 0.4117647058823529, 0.7777777777777778, 0.6428571428571428,
0.9444444444444444, 0.5, 0.3939393939393939, 0.5, 0.3793103448275862,
0.36111111111111116, 0.18181818181818177, 0.33333333333333337,
0.5333333333333333, 0.6666666666666667, 0.1923076923076923, 0.44999999999999996,
0.6470588235294117, 0.736842105263158, 0.43181818181818177, 0.4482758620689655,
0.43999999999999995, 0.43333333333333335, 0.7297297297297297,
0.43999999999999995, 0.6818181818181819, 0.6031746031746033, 0.5094339622641509,
0.6, 0.6382978723404256, 0.5111111111111111, 0.12121212121212122, 0.64,
0.5161290322580645, 0.6818181818181819, 0.45833333333333337, 0.5,
0.46153846153846156, 0.40909090909090906, 0.5333333333333333,
0.4642857142857143, 0.631578947368421, 0.41463414634146345, 0.40625,
0.44999999999999996, 0.375, 0.6052631578947368, 0.7083333333333333,
0.5806451612903225, 0.38888888888888884, 0.5102040816326531, 0.1923076923076923,
0.40909090909090906, 0.625, 0.625, 0.4871794871794872, 0.2571428571428571,
0.4651162790697675, 0.3783783783783784, 0.38636363636363635, 0.6538461538461539,
0.7307692307692308, 0.8333333333333334, 0.4736842105263158, 0.7741935483870968,
0.9047619047619048, 0.6666666666666667, 0.5, 0.6785714285714286,
0.6785714285714286, 0.5652173913043479, 0.7333333333333334, 0.8125,
0.7777777777777778, 0.43999999999999995, 0.6428571428571428, 0.6666666666666667,
0.3666666666666667, 0.47058823529411764, 0.75, 0.3125, 0.4, 0.4516129032258065,
0.5, 0.5102040816326531, 0.6296296296296297, 0.6451612903225806, 0.36,
0.18181818181818177, 0.6585365853658536, 0.18181818181818177,
0.47619047619047616, 0.7551020408163265, 0.42307692307692313,
0.5283018867924528, 0.7058823529411764, 0.6166666666666667, 0.5294117647058824,
0.24, 0.4054054054054054, 0.43243243243243246, 0.29729729729729726, 0.75,
0.47619047619047616, 0.85, 0.75, 0.3913043478260869, 0.44897959183673475,
0.33333333333333337, 0.525, 0.6, 0.6666666666666667, 0.5555555555555556,
0.6111111111111112, 0.6111111111111112, 0.5454545454545454, 0.42105263157894735,
0.3571428571428571, 0.6521739130434783, 0.40625, 0.5416666666666667,
0.3846153846153846, 0.64, 0.11764705882352944, 0.48888888888888893,
0.3653846153846154, 0.9705882352941176, 0.37142857142857144, 0.2592592592592593,
0.6756756756756757, 0.6097560975609756, 0.28125, 0.16000000000000003,
0.45569620253164556, 0.5714285714285714, 0.6666666666666667, 0.6666666666666667,
0.76, 0.14, 0.20512820512820518, 0.9545454545454546, 0.47619047619047616,
0.4385964912280702, 0.11363636363636365, 0.32432432432432434, 0.631578947368421,
0.6896551724137931, 0.5365853658536586, 0.47619047619047616, 0.5925925925925926,
0.39583333333333337, 0.23529411764705888, 0.30434782608695654,
0.47058823529411764, 0.3548387096774194, 0.8918918918918919, 0.5185185185185186,
0.7045454545454546, 0.6153846153846154, 0.875, 0.3870967741935484,
0.9090909090909091, 0.6296296296296297, 0.8636363636363636, 0.4193548387096774,
0.6296296296296297, 0.3793103448275862, 0.6976744186046512, 0.9, 0.6,
0.34285714285714286, 0.34285714285714286, 0.3055555555555556, 0.36,
0.5714285714285714, 0.641025641025641, 0.6, 0.3555555555555555,
0.6842105263157895, 0.4642857142857143, 0.6037735849056604, 0.36363636363636365,
0.5789473684210527, 0.33333333333333337, 0.8461538461538461, 0.368421052631579,
0.5833333333333333, 0.8333333333333334, 0.5925925925925926, 0.53125,
0.38888888888888884, 0.5294117647058824, 0.3548387096774194, 1.0,
0.5172413793103448, 0.5483870967741935, 0.6666666666666667, 0.36,
0.5517241379310345, 0.47916666666666663, 0.7037037037037037, 0.6363636363636364,
0.6363636363636364, 0.368421052631579, 0.4, 0.4482758620689655, 0.4375,
0.34285714285714286, 0.5652173913043479, 0.4411764705882353, 0.6, 0.4,
0.8269230769230769, 0.8888888888888888, 0.5526315789473684, 0.47058823529411764,
0.5925925925925926, 0.34782608695652173, 0.96875, 0.6666666666666667, 0.5,
0.23076923076923073, 0.782608695652174, 0.46875, 0.8823529411764706, 0.65,
0.6666666666666667, 0.26315789473684215, 0.31818181818181823,
0.6363636363636364, 0.5909090909090908, 0.41666666666666663,
0.26086956521739135, 0.46153846153846156, 0.4482758620689655,
0.22857142857142854, 0.47058823529411764, 0.9375, 0.4782608695652174,
0.5238095238095238, 0.5476190476190477, 0.5, 0.5, 0.21052631578947367,
0.9444444444444444, 1.0, 0.5294117647058824, 0.3132530120481928,
0.4242424242424242, 0.23333333333333328, 0.10256410256410253, 0.0,
0.3111111111111111, 0.3282442748091603, 0.2549019607843137, 0.38095238095238093,
0.6086956521739131, 0.4666666666666667, 0.7916666666666666, 0.7272727272727273,
0.38095238095238093, 0.4242424242424242, 0.6470588235294117, 0.7407407407407407,
0.24444444444444446, 0.9, 0.8108108108108107, 0.7083333333333333,
0.6111111111111112, 0.5, 0.2592592592592593, 0.95, 0.95, 0.37142857142857144,
0.8888888888888888, 0.3846153846153846, 0.34615384615384615, 0.4411764705882353,
0.17391304347826086, 0.5238095238095238, 0.40384615384615385,
0.3666666666666667, 0.25, 0.5, 0.34782608695652173, 0.5714285714285714,
0.7222222222222222, 0.7222222222222222, 0.3666666666666667, 0.33333333333333337,
0.33333333333333337, 0.33333333333333337, 0.5185185185185186,
0.40384615384615385, 0.19999999999999996, 0.6666666666666667,
0.5217391304347826, 0.2702702702702703, 0.65, 0.8478260869565217,
0.782608695652174, 0.95, 0.5, 0.5555555555555556, 0.43333333333333335,
0.3913043478260869, 0.7692307692307692, 1.0, 0.3589743589743589,
0.33333333333333337, 0.9090909090909091, 0.6875, 0.5, 0.30000000000000004,
0.5111111111111111, 0.8787878787878788, 0.6415094339622642, 0.65, 0.25,
0.26315789473684215, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764,
0.37037037037037035, 0.7222222222222222, 0.6595744680851063, 0.625,
0.7333333333333334, 0.875, 0.8709677419354839, 0.8387096774193549, 0.65,
0.29166666666666663, 0.3157894736842105, 0.4736842105263158, 0.4,
0.5454545454545454, 0.23684210526315785, 0.5, 0.05555555555555558,
0.6470588235294117, 0.2727272727272727, 0.9375, 0.7083333333333333,
0.9166666666666666, 0.7647058823529411, 0.2727272727272727, 0.64,
0.5384615384615384, 0.64, 0.8108108108108107, 0.75, 0.75, 0.7894736842105263,
0.3571428571428571, 0.9545454545454546, 0.736842105263158, 0.9285714285714286,
0.8333333333333334, 0.3076923076923077, 0.64, 0.13888888888888884,
0.27586206896551724, 0.29268292682926833, 0.5, 1.0, 0.4864864864864865,
0.34782608695652173, 0.9166666666666666, 0.6428571428571428, 0.8888888888888888,
0.34090909090909094, 0.5365853658536586, 0.42307692307692313,
0.5238095238095238, 0.6, 0.625, 0.3902439024390244, 0.5094339622641509,
0.5428571428571429, 0.4242424242424242, 0.6521739130434783, 0.43243243243243246,
0.5483870967741935, 0.368421052631579, 1.0, 0.6818181818181819, 0.5,
0.7058823529411764, 0.875, 0.375, 0.28, 0.6976744186046512, 0.6111111111111112,
0.5365853658536586, 0.4, 0.7567567567567568, 0.41463414634146345,
0.3076923076923077, 0.48484848484848486, 0.30000000000000004, 1.0,
0.5217391304347826, 0.5681818181818181, 0.65, 0.94, 0.3928571428571429, 0.3125,
0.125, 0.5384615384615384, 0.7857142857142857, 0.8571428571428572,
0.5263157894736843, 0.8666666666666667, 0.4736842105263158, 0.8,
0.7241379310344828, 0.47058823529411764, 0.2666666666666667, 0.4,
0.6428571428571428, 0.5, 0.7894736842105263, 0.21212121212121215, 0.5,
0.6842105263157895, 0.2222222222222222, 0.7272727272727273, 0.3921568627450981,
0.375, 0.8333333333333334, 0.6129032258064516, 0.15384615384615385, 0.95,
0.43333333333333335, 0.5882352941176471, 0.4418604651162791,
0.37037037037037035]\}\})
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{271}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{stats}
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model A}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilcoxon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
                \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{,} \PY{n}{alternative}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{less}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}\PY{p}{,} \PY{n}{display}
\PY{k+kn}{import} \PY{n+nn}{tabulate}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{statistics-for-humans}{%
\subsection{Statistics for humans}\label{statistics-for-humans}}

    Here we clean up the human grades dataset and compute Wilcoxon test
(similarly to what we did with the metric scores). As there are 8 points
missing in Egor grades, I have submitted my scores for them. This is
dirty and I will fix this later, but this can hardly affect the results
(8 points correspond to 0.3\% sample points)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{208}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{data\PYZus{}misha} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{to\PYZhy{}grade/all\PYZhy{}singles\PYZhy{}done.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\PY{n}{data\PYZus{}egor} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{to\PYZhy{}grade/all\PYZhy{}singles.egor.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{209}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grade\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{data\PYZus{}egor}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
        \PY{k}{if} \PY{n}{entry}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{n}\PY{p}{)} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{211}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
                \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
                    \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}egor} \PY{o}{=} \PY{p}{[}\PY{n}{data\PYZus{}egor}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{212}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{data\PYZus{}misha}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
        \PY{k}{if} \PY{n}{entry}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{n}\PY{p}{)} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{213}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}misha}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}misha}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
                \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
                    \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}misha} \PY{o}{=} \PY{p}{[}\PY{n}{data}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{214}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grades\PYZus{}misha} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}misha}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{all\PYZus{}fields}\PY{p}{:}
        \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{myroundlist}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{215}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grades\PYZus{}egor} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{entry} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{clean\PYZus{}egor}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{all\PYZus{}fields}\PY{p}{:}
        \PY{k}{try}\PY{p}{:}
            \PY{n}{tmp} \PY{o}{=} \PY{n}{myroundlist}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
        \PY{k}{except}\PY{p}{:} 
            \PY{n}{tmp} \PY{o}{=} \PY{n}{myroundlist}\PY{p}{(}\PY{n}{clean\PYZus{}misha}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
        \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{269}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Grader}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model A}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilcoxon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{,} \PY{n}{alternative}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{less}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{,} \PY{n}{alternative}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{less}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}\PY{p}{,} \PY{n}{display}
\PY{k+kn}{import} \PY{n+nn}{tabulate}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{correlations}{%
\subsection{Correlations}\label{correlations}}

    Here we compute Spearman r and Kendall tau for all pairs of metrics and
graders. As we want to compare across all datasets, we concatenate the
lists for each dataset together.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{217}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric 2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Spearman}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Kendall tau}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{n}{all\PYZus{}grades} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{=} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
\PY{n}{gradesm} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{gradese} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{gradesm} \PY{o}{=} \PY{n}{gradesm} \PY{o}{+} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field}\PY{p}{]}
    \PY{n}{gradese} \PY{o}{=} \PY{n}{gradese} \PY{o}{+} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field}\PY{p}{]}

\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{metric1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{metric2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{grades1} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{n}{grades2} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
                \PY{n}{grades1} \PY{o}{=} \PY{n}{grades1} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
                \PY{n}{grades2} \PY{o}{=} \PY{n}{grades2} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{n}{metric2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradese}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradese}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{}gradesm = gradesm + grades\PYZus{}misha[\PYZsq{}snippet\PYZsq{}]}
\PY{c+c1}{\PYZsh{}gradese = gradese + grades\PYZus{}egor[\PYZsq{}snippet\PYZsq{}]}
\PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{gradese}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{gradese}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}\PY{p}{,} \PY{n}{display}
\PY{k+kn}{import} \PY{n+nn}{tabulate}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{=} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{+} \PY{p}{[}\PY{l+m+mf}{1.0} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{p}{)}\PY{p}{]} \PY{c+c1}{\PYZsh{}for the reference snippet}
\PY{n}{gradesm} \PY{o}{=} \PY{n}{gradesm} \PY{o}{+} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{gradese} \PY{o}{=} \PY{n}{gradese} \PY{o}{+} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{logistic-regression}{%
\subsection{Logistic regression}\label{logistic-regression}}

    Here we train logistic regression to infer the human grades from the
computer metrics

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{218}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{seedbleu} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{o}{*}\PY{n}{i} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1001}\PY{p}{)}\PY{p}{]}
\PY{n}{logus} \PY{o}{=} \PY{p}{[}\PY{n}{myround}\PY{p}{(}\PY{n}{gradese}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gradese}\PY{p}{)}\PY{p}{)}\PY{p}{]}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LogisticRegression}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{n}{bleulog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{bleulog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outbleu} \PY{o}{=} \PY{n}{bleulog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{metlog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{metlog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outmet} \PY{o}{=} \PY{n}{metlog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{roulog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{roulog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outrou} \PY{o}{=} \PY{n}{roulog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outmet} \PY{o}{=} \PY{n}{metlog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{rubylog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{rubylog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outruby} \PY{o}{=} \PY{n}{rubylog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
    \end{Verbatim}

    The following two cells give a distribution of probability for the sum
of inferred human grades for every snippet in a dataset

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{219}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{contract\PYZus{}prob}\PY{p}{(}\PY{n}{biglist}\PY{p}{,} \PY{n}{smlist}\PY{p}{,} \PY{n}{cut}\PY{p}{)}\PY{p}{:}
    \PY{n}{outlist} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{biglist}\PY{p}{)}\PY{p}{)}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{cut}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{smlist}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{outlist}\PY{p}{[}\PY{n}{i}\PY{o}{+}\PY{n}{j}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{n}{biglist}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{*}\PY{n}{smlist}\PY{p}{[}\PY{n}{j}\PY{p}{]}
    \PY{k}{return} \PY{n}{outlist}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{221}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{metrics} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{m2} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outbleu}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outrou}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outmet}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outruby}\PY{p}{\PYZcb{}}
\PY{n}{probdict} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{)}
\PY{c+c1}{\PYZsh{}problist = [0]*2001}
\PY{c+c1}{\PYZsh{}problist[0] = 1}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{names}\PY{p}{:}
        \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{o}{*}\PY{n+nb}{len}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}
        \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{n}{cut} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{:}
            \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]} \PY{o}{=} \PY{n}{contract\PYZus{}prob}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{,} \PY{n}{m2}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{l+m+mi}{1000}\PY{o}{*}\PY{n+nb}{round}\PY{p}{(}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{,} \PY{n}{cut}\PY{p}{)}
            \PY{n}{cut} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{4}
\end{Verbatim}
\end{tcolorbox}

    Here we use the obtained probability distribution to compute the
probability that model 2 will have higher inferred human grade than
model 1

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{222}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model 2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(2 \PYZgt{} 1)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{nam1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{names}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{nam2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{names}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{j} \PY{o}{\PYZlt{}} \PY{n}{k}\PY{p}{:}
                \PY{n}{comp\PYZus{}prob} \PY{o}{=} \PY{l+m+mi}{0}
                \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam1}\PY{p}{]}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                    \PY{n}{comp\PYZus{}prob} \PY{o}{+}\PY{o}{=} \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam1}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{*}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam2}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}
                \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric}\PY{p}{,} \PY{n}{nam1}\PY{p}{,} \PY{n}{nam2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{comp\PYZus{}prob}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}                          
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{worst-case-scenario-for-bleu-etc.}{%
\section{Worst-case scenario for BLEU
etc.}\label{worst-case-scenario-for-bleu-etc.}}

    Here we consider the case when only one of the references out of few is
available and check whether this can disrupt computer metrics

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{199}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}dirty\PYZus{}dataset = json.load(open(\PYZsq{}./metrics\PYZhy{}evaluation/to\PYZhy{}grade/all\PYZhy{}singles.json\PYZsq{}))}
\PY{n}{dirty\PYZus{}dataset} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./to\PYZhy{}grade/all\PYZhy{}singles.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{dirty\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{v} \PY{o+ow}{in} \PY{n}{d}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        \PY{n}{d}\PY{p}{[}\PY{n}{k}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{v}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{200}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{all\PYZus{}names}\PY{p}{:}
                \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}dataset} \PY{o}{=} \PY{p}{[}\PY{n}{dirty\PYZus{}dataset}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{dirty\PYZus{}dataset}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{bleu}{%
\subsection{BLEU}\label{bleu}}

    This (and the next following sections) correspond to the metric
computation. The only thing to notice is that BLEU results depend on the
smoothing function (smooth = SmoothingFunction().method\#; \# is the
number from 1 to 5). In the end we get updated clean\_dataset with all
grades for all metrics

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{261}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{find\PYZus{}opt}\PY{p}{(}\PY{n}{d}\PY{p}{)}\PY{p}{:}
    \PY{n}{snp} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{sn}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{sn} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
    \PY{n}{ta} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{hp}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{hp} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
    \PY{n}{bt} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{hp}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{hp} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
    \PY{n}{btr} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{hp}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{hp} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
    \PY{n}{opt\PYZus{}ta} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}
    \PY{n}{opt\PYZus{}bt} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{sn} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{snp}\PY{p}{)}\PY{p}{:}
        \PY{n}{ta\PYZus{}score} \PY{o}{=} \PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{sn}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{ta}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{bt\PYZus{}score} \PY{o}{=} \PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{sn}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{bt}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{btr\PYZus{}score} \PY{o}{=} \PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{sn}\PY{p}{]}\PY{p}{]}\PY{p}{,} \PY{n}{btr}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{c+c1}{\PYZsh{}        print(ta\PYZus{}score\PYZhy{}bt\PYZus{}score)}
        \PY{k}{if} \PY{n}{opt\PYZus{}ta} \PY{o}{\PYZlt{}} \PY{p}{(}\PY{n}{ta\PYZus{}score} \PY{o}{\PYZhy{}} \PY{n}{bt\PYZus{}score}\PY{p}{)}\PY{p}{:}
            \PY{n}{i\PYZus{}ta} \PY{o}{=} \PY{n}{i}
            \PY{n}{opt\PYZus{}ta} \PY{o}{=} \PY{p}{(}\PY{n}{ta\PYZus{}score} \PY{o}{\PYZhy{}} \PY{n}{bt\PYZus{}score}\PY{p}{)}
        \PY{k}{if} \PY{n}{opt\PYZus{}bt} \PY{o}{\PYZlt{}} \PY{p}{(}\PY{n}{bt\PYZus{}score} \PY{o}{\PYZhy{}} \PY{n}{btr\PYZus{}score}\PY{p}{)}\PY{p}{:}
            \PY{n}{i\PYZus{}bt} \PY{o}{=} \PY{n}{i}
            \PY{n}{opt\PYZus{}bt} \PY{o}{=} \PY{p}{(}\PY{n}{bt\PYZus{}score} \PY{o}{\PYZhy{}} \PY{n}{btr\PYZus{}score}\PY{p}{)}
    \PY{k}{return} \PY{n}{i\PYZus{}ta}\PY{p}{,} \PY{n}{i\PYZus{}bt}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{262}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{find\PYZus{}opt}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{262}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(1, 0)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{263}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{i\PYZus{}ta} \PY{o}{=} \PY{n}{i\PYZus{}bt} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{1}\PY{p}{:}\PY{c+c1}{\PYZsh{}first stands for the closest possible tranx\PYZhy{}annot to best\PYZhy{}tranx}
            \PY{n}{i\PYZus{}ta}\PY{p}{,} \PY{n}{i\PYZus{}bt} \PY{o}{=} \PY{n}{find\PYZus{}opt}\PY{p}{(}\PY{n}{d}\PY{p}{)}
        \PY{n}{hyp} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{hp}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{hp} \PY{o+ow}{in} \PY{n}{d}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}            
        \PY{n}{snpf} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{sn}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{sn} \PY{o+ow}{in} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{n}{i\PYZus{}ta}\PY{p}{]}\PY{p}{]}\PY{p}{]}
        \PY{n}{snpl} \PY{o}{=} \PY{p}{[}\PY{n}{tknz}\PY{p}{(}\PY{n}{sn}\PY{o}{.}\PY{n}{strip}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{sn} \PY{o+ow}{in} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{n}{i\PYZus{}bt}\PY{p}{]}\PY{p}{]}\PY{p}{]}
        \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first\PYZhy{}grade\PYZhy{}bleu\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{n}{snpf}\PY{p}{]}\PY{p}{,} \PY{n}{hyp}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZhy{}grade\PYZhy{}bleu\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{compute\PYZus{}bleu}\PY{p}{(}\PY{p}{[}\PY{n}{snpl}\PY{p}{]}\PY{p}{,} \PY{n}{hyp}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{233}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{clean\PYZus{}dataset}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{233}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\{'intent': ['get rid of None values in dictionary `kwargs`'],
 'snippet': ['res = \{k: v for k, v in list(kwargs.items()) if v is not None\}',
  'res = dict((k, v) for k, v in kwargs.items() if v is not None)'],
 'baseline': ['sum(d,v)for k,v in list(d.items()))',
  'sum(d,v)for k,v in list(d.items()))'],
 'tranx-annot': ['print(dict(( k,v)for k,v in kwargs.items() if v))',
  'print(dict(( k,v)for k,v in kwargs.items() if v))'],
 'best-tranx': ['list(kwargs.values())', 'list(kwargs.values())'],
 'best-tranx-rerank': ['list(kwargs.values())', 'list(kwargs.values())'],
 'grade-bleu-baseline': 0.5052,
 'grade-bleu-tranx-annot': 0.7655,
 'grade-bleu-best-tranx': 0.0597,
 'grade-bleu-best-tranx-rerank': 0.0597,
 'grade-rougel-baseline': 0.6222,
 'grade-rougel-tranx-annot': 0.75,
 'grade-rougel-best-tranx': 0.3939,
 'grade-rougel-best-tranx-rerank': 0.3939,
 'grade-meteor-baseline': 0.5045,
 'grade-meteor-tranx-annot': 0.7956,
 'grade-meteor-best-tranx': 0.2969,
 'grade-meteor-best-tranx-rerank': 0.2969,
 'grade-ruby-baseline': 0.48,
 'grade-ruby-tranx-annot': 0.8666666666666667,
 'grade-ruby-best-tranx': 0.2564102564102564,
 'grade-ruby-best-tranx-rerank': 0.2564102564102564,
 'first-grade-bleu-baseline': 0.3748,
 'last-grade-bleu-baseline': 0.3885,
 'first-grade-bleu-tranx-annot': 0.3577,
 'last-grade-bleu-tranx-annot': 0.7553,
 'first-grade-bleu-best-tranx': 0.0597,
 'last-grade-bleu-best-tranx': 0.0,
 'first-grade-bleu-best-tranx-rerank': 0.0597,
 'last-grade-bleu-best-tranx-rerank': 0.0\}
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{rouge-l}{%
\subsection{ROUGE-L}\label{rouge-l}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{244}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{evaluator} \PY{o}{=} \PY{n}{rouge}\PY{o}{.}\PY{n}{Rouge}\PY{p}{(}\PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}l}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                           \PY{n}{max\PYZus{}n}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}
                           \PY{n}{limit\PYZus{}length}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
                           \PY{n}{length\PYZus{}limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}
                           \PY{n}{length\PYZus{}limit\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{words}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{c+c1}{\PYZsh{} Default F1\PYZus{}score}
                           \PY{n}{weight\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{1.2}\PY{p}{)}
\PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{keynf} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first\PYZhy{}grade\PYZhy{}rougel\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{nam}
    \PY{n}{keynl} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZhy{}grade\PYZhy{}rougel\PYZhy{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{nam}
    \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
        \PY{n}{hypt} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{refrf} \PY{o}{=} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}
        \PY{n}{refrl} \PY{o}{=} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
        \PY{k}{if} \PY{n}{hypt} \PY{o+ow}{is} \PY{o+ow}{not} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
            \PY{n}{scores} \PY{o}{=} \PY{n}{evaluator}\PY{o}{.}\PY{n}{get\PYZus{}scores}\PY{p}{(}\PY{n}{hypt}\PY{p}{,} \PY{n}{refrf}\PY{p}{)}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynf}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}l}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
            \PY{n}{scores} \PY{o}{=} \PY{n}{evaluator}\PY{o}{.}\PY{n}{get\PYZus{}scores}\PY{p}{(}\PY{n}{hypt}\PY{p}{,} \PY{n}{refrl}\PY{p}{)}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynl}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{scores}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rouge\PYZhy{}l}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynf}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynl}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{meteor}{%
\subsection{METEOR}\label{meteor}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{245}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{keynf} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first\PYZhy{}grade\PYZhy{}meteor\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{nam}
    \PY{n}{keynl} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZhy{}grade\PYZhy{}meteor\PYZhy{}}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{nam}
    \PY{k}{for} \PY{n}{d} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
        \PY{n}{hypt} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{refrf} \PY{o}{=} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}
        \PY{n}{refrl} \PY{o}{=} \PY{p}{[}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
        \PY{k}{if} \PY{n}{hypt} \PY{o+ow}{is} \PY{o+ow}{not} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynf}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{mym}\PY{o}{.}\PY{n}{meteor\PYZus{}score}\PY{p}{(}\PY{n}{refrf}\PY{p}{,} \PY{n}{hypt}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynl}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{mym}\PY{o}{.}\PY{n}{meteor\PYZus{}score}\PY{p}{(}\PY{n}{refrl}\PY{p}{,} \PY{n}{hypt}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynf}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
            \PY{n}{d}\PY{p}{[}\PY{n}{keynl}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{ruby}{%
\subsection{RUBY}\label{ruby}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{204}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{ruby}\PY{n+nn}{.}\PY{n+nn}{similarity} \PY{k}{import} \PY{n}{ruby} \PY{k}{as} \PY{n}{ruby}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{242}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{ruby\PYZus{}grade} \PY{o}{=} \PY{l+m+mf}{0.0}
        \PY{n}{sample} \PY{o}{=} \PY{n}{entry}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{`}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first\PYZhy{}grade\PYZhy{}ruby\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{n}{ruby}\PY{p}{(}\PY{n}{sample}\PY{p}{,} \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}    
        \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZhy{}grade\PYZhy{}ruby\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{n}{ruby}\PY{p}{(}\PY{n}{sample}\PY{p}{,} \PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}    
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{statistical-tests-for-computer-metrics}{%
\subsection{Statistical tests for computer
metrics}\label{statistical-tests-for-computer-metrics}}

    Here we split all grades for all metrics into a dictionary of
dictionaries that has metric and model as keys and list of all grades as
a value. We then use it to run Wilcoxon signed-rank test

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{264}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{first\PYZus{}split\PYZus{}grades} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{first\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
        \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
            \PY{n}{first\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first\PYZhy{}grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{metric}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
\PY{n}{last\PYZus{}split\PYZus{}grades} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{last\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}dataset}\PY{p}{:}
    \PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
        \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
            \PY{n}{last\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZhy{}grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{metric}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{265}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model A}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilcoxon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
                \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{first\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{first\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{first}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model A}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilcoxon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{:}
    \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
                \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{last\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{last\PYZus{}split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}                
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
first
    \end{Verbatim}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
last
    \end{Verbatim}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{statistics-for-humans}{%
\subsection{Statistics for humans}\label{statistics-for-humans}}

    Here we clean up the human grades dataset and compute Wilcoxon test
(similarly to what we did with the metric scores). As there are 8 points
missing in Egor grades, I have submitted my scores for them. This is
dirty and I will fix this later, but this can hardly affect the results
(8 points correspond to 0.3\% sample points)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{208}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{data\PYZus{}misha} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{to\PYZhy{}grade/all\PYZhy{}singles\PYZhy{}done.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\PY{n}{data\PYZus{}egor} \PY{o}{=} \PY{n}{json}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{to\PYZhy{}grade/all\PYZhy{}singles.egor.json}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{209}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grade\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{data\PYZus{}egor}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
        \PY{k}{if} \PY{n}{entry}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{n}\PY{p}{)} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{211}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
                \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
                    \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}egor} \PY{o}{=} \PY{p}{[}\PY{n}{data\PYZus{}egor}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data\PYZus{}egor}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{212}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{data\PYZus{}misha}\PY{p}{:}
    \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
        \PY{k}{if} \PY{n}{entry}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{n}\PY{p}{)} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{]}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{entry}\PY{p}{[}\PY{n}{n}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{213}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{to\PYZus{}remove} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{d1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}misha}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{d2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data\PYZus{}misha}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{p}{(}\PY{p}{(}\PY{n}{i}\PY{o}{\PYZlt{}}\PY{n}{j}\PY{p}{)} \PY{o+ow}{and} \PY{p}{(}\PY{n}{d1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{n}{d2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{intent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{to\PYZus{}remove}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{j}\PY{p}{)}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{grade\PYZus{}names}\PY{p}{:}
                \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{:}
                    \PY{n}{d1}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{d2}\PY{p}{[}\PY{n}{n}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{n}{clean\PYZus{}misha} \PY{o}{=} \PY{p}{[}\PY{n}{data}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)} \PY{k}{if} \PY{n}{j} \PY{o+ow}{not} \PY{o+ow}{in} \PY{n}{to\PYZus{}remove}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{214}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grades\PYZus{}misha} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{entry} \PY{o+ow}{in} \PY{n}{clean\PYZus{}misha}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{all\PYZus{}fields}\PY{p}{:}
        \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{myroundlist}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{215}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{grades\PYZus{}egor} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{entry} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{clean\PYZus{}egor}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{all\PYZus{}fields}\PY{p}{:}
        \PY{k}{try}\PY{p}{:}
            \PY{n}{tmp} \PY{o}{=} \PY{n}{myroundlist}\PY{p}{(}\PY{n}{entry}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
        \PY{k}{except}\PY{p}{:} 
            \PY{n}{tmp} \PY{o}{=} \PY{n}{myroundlist}\PY{p}{(}\PY{n}{clean\PYZus{}misha}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grade\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n}{field}\PY{p}{]}\PY{p}{)}
        \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tmp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{216}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Grader}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model A}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Wilcoxon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{field1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{field2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{field1}\PY{p}{,} \PY{n}{field2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{wilcoxon}\PY{p}{(}\PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field1}\PY{p}{]}\PY{p}{,} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}\PY{p}{,} \PY{n}{display}
\PY{k+kn}{import} \PY{n+nn}{tabulate}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{correlations}{%
\subsection{Correlations}\label{correlations}}

    Here we compute Spearman r and Kendall tau for all pairs of metrics and
graders. As we want to compare across all datasets, we concatenate the
lists for each dataset together.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{217}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric 2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Spearman}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Kendall tau}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
\PY{n}{all\PYZus{}grades} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
        \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{=} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
\PY{n}{gradesm} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{gradese} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
    \PY{n}{gradesm} \PY{o}{=} \PY{n}{gradesm} \PY{o}{+} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{n}{field}\PY{p}{]}
    \PY{n}{gradese} \PY{o}{=} \PY{n}{gradese} \PY{o}{+} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{n}{field}\PY{p}{]}

\PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{metric1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{p}{)}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{metric2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{metrics}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{i} \PY{o}{\PYZlt{}} \PY{n}{j}\PY{p}{:}
            \PY{n}{grades1} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{n}{grades2} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            \PY{k}{for} \PY{n}{field} \PY{o+ow}{in} \PY{n}{fields}\PY{p}{:}
                \PY{n}{grades1} \PY{o}{=} \PY{n}{grades1} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
                \PY{n}{grades2} \PY{o}{=} \PY{n}{grades2} \PY{o}{+} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{[}\PY{n}{field}\PY{p}{]}
            \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{n}{metric2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric2}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradese}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric1}\PY{p}{]}\PY{p}{,} \PY{n}{gradese}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{}gradesm = gradesm + grades\PYZus{}misha[\PYZsq{}snippet\PYZsq{}]}
\PY{c+c1}{\PYZsh{}gradese = gradese + grades\PYZus{}egor[\PYZsq{}snippet\PYZsq{}]}
\PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Egor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Misha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{spearmanr}\PY{p}{(}\PY{n}{gradese}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{kendalltau}\PY{p}{(}\PY{n}{gradese}\PY{p}{,} \PY{n}{gradesm}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}\PY{p}{,} \PY{n}{display}
\PY{k+kn}{import} \PY{n+nn}{tabulate}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{=} \PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]} \PY{o}{+} \PY{p}{[}\PY{l+m+mf}{1.0} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{p}{)}\PY{p}{]} \PY{c+c1}{\PYZsh{}for the reference snippet}
\PY{n}{gradesm} \PY{o}{=} \PY{n}{gradesm} \PY{o}{+} \PY{n}{grades\PYZus{}misha}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{gradese} \PY{o}{=} \PY{n}{gradese} \PY{o}{+} \PY{n}{grades\PYZus{}egor}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{snippet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    \hypertarget{logistic-regression}{%
\subsection{Logistic regression}\label{logistic-regression}}

    Here we train logistic regression to infer the human grades from the
computer metrics

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{218}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{seedbleu} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.001}\PY{o}{*}\PY{n}{i} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1001}\PY{p}{)}\PY{p}{]}
\PY{n}{logus} \PY{o}{=} \PY{p}{[}\PY{n}{myround}\PY{p}{(}\PY{n}{gradese}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{gradesm}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gradese}\PY{p}{)}\PY{p}{)}\PY{p}{]}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LogisticRegression}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{n}{bleulog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{bleulog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outbleu} \PY{o}{=} \PY{n}{bleulog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{metlog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{metlog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outmet} \PY{o}{=} \PY{n}{metlog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{roulog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{roulog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outrou} \PY{o}{=} \PY{n}{roulog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outmet} \PY{o}{=} \PY{n}{metlog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{rubylog} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{rubylog}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{all\PYZus{}grades}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{logus}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\PY{n}{outruby} \PY{o}{=} \PY{n}{rubylog}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{seedbleu}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:432:
FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a
solver to silence this warning.
  FutureWarning)
/opt/anaconda/lib/python3.7/site-packages/sklearn/utils/validation.py:724:
DataConversionWarning: A column-vector y was passed when a 1d array was
expected. Please change the shape of y to (n\_samples, ), for example using
ravel().
  y = column\_or\_1d(y, warn=True)
/opt/anaconda/lib/python3.7/site-packages/sklearn/linear\_model/logistic.py:469:
FutureWarning: Default multi\_class will be changed to 'auto' in 0.22. Specify
the multi\_class option to silence this warning.
  "this warning.", FutureWarning)
    \end{Verbatim}

    The following two cells give a distribution of probability for the sum
of inferred human grades for every snippet in a dataset

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{219}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{contract\PYZus{}prob}\PY{p}{(}\PY{n}{biglist}\PY{p}{,} \PY{n}{smlist}\PY{p}{,} \PY{n}{cut}\PY{p}{)}\PY{p}{:}
    \PY{n}{outlist} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{biglist}\PY{p}{)}\PY{p}{)}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{cut}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{smlist}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{outlist}\PY{p}{[}\PY{n}{i}\PY{o}{+}\PY{n}{j}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{n}{biglist}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{*}\PY{n}{smlist}\PY{p}{[}\PY{n}{j}\PY{p}{]}
    \PY{k}{return} \PY{n}{outlist}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{221}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{baseline}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tranx\PYZhy{}annot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best\PYZhy{}tranx\PYZhy{}rerank}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{metrics} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{m2} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bleu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outbleu}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rougel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outrou}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{meteor}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outmet}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ruby}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{outruby}\PY{p}{\PYZcb{}}
\PY{n}{probdict} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{dict}\PY{p}{)}
\PY{c+c1}{\PYZsh{}problist = [0]*2001}
\PY{c+c1}{\PYZsh{}problist[0] = 1}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{nam} \PY{o+ow}{in} \PY{n}{names}\PY{p}{:}
        \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{o}{*}\PY{n+nb}{len}\PY{p}{(}\PY{n}{clean\PYZus{}dataset}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}
        \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{n}{cut} \PY{o}{=} \PY{l+m+mi}{1}
        \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n}{split\PYZus{}grades}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{:}
            \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]} \PY{o}{=} \PY{n}{contract\PYZus{}prob}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam}\PY{p}{]}\PY{p}{,} \PY{n}{m2}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{l+m+mi}{1000}\PY{o}{*}\PY{n+nb}{round}\PY{p}{(}\PY{n}{j}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{,} \PY{n}{cut}\PY{p}{)}
            \PY{n}{cut} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{4}
\end{Verbatim}
\end{tcolorbox}

    Here we use the obtained probability distribution to compute the
probability that model 2 will have higher inferred human grade than
model 1

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{222}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tmp} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model 2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{P(2 \PYZgt{} 1)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
    \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{nam1} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{names}\PY{p}{)}\PY{p}{:}
        \PY{k}{for} \PY{n}{k}\PY{p}{,} \PY{n}{nam2} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{names}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{j} \PY{o}{\PYZlt{}} \PY{n}{k}\PY{p}{:}
                \PY{n}{comp\PYZus{}prob} \PY{o}{=} \PY{l+m+mi}{0}
                \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam1}\PY{p}{]}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                    \PY{n}{comp\PYZus{}prob} \PY{o}{+}\PY{o}{=} \PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam1}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{*}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{probdict}\PY{p}{[}\PY{n}{metric}\PY{p}{]}\PY{p}{[}\PY{n}{nam2}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}
                \PY{n}{tmp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{metric}\PY{p}{,} \PY{n}{nam1}\PY{p}{,} \PY{n}{nam2}\PY{p}{,} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{comp\PYZus{}prob}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{n}{tabulate}\PY{o}{.}\PY{n}{tabulate}\PY{p}{(}\PY{n}{tmp}\PY{p}{,} \PY{n}{tablefmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{html}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}                          
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    

    % Add a bibliography block to the postdoc
    
    
    
\end{document}
